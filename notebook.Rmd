---
title: "R Notebook for the cystectomy study"
author: "Pascal Jerney"
date: "11th August 2020"
output:
  bookdown::gitbook:
    config:
      toc:
        collapse: subsection
        scroll_highlight: yes
        before: null
        after: null
      toolbar:
        position: fixed
      edit : null
      download:
        - ["notebook.pdf", "PDF"]
      search: yes
      fontsettings:
        theme: white
        family: sans
        size: 2
      sharing:
        facebook: yes
        github: no
        twitter: yes
        linkedin: no
        weibo: no
        instapaper: no
        vk: no
        all: ['facebook', 'twitter', 'linkedin', 'weibo', 'instapaper']
      info: yes
  html_notebook: default
  bookdown::pdf_document2:
    toc: false
    keep_tex: true
    latex_engine: xelatex
---

```{r setup, echo=FALSE}
# Load packages ----
if (!require("pacman")) {
  install.packages("pacman")
}
pacman::p_load(
  "tidyverse",
  "rprojroot",
  "fs",
  "tableone",
  "modelr",
  "glue",
  "gridExtra",
  "pander",
  "htmltools",
  "MASS",
  "car",
  "recipes",
  "ROCR",
  "DALEX",
  "caret"
)
pacman::p_unload("MASS")

# Set working directory ----
setwd(rprojroot::find_rstudio_root_file())
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png",
  dpi = 300,
  fig.asp = 0.8,
  fig.width = 10,
  out.width = "100%",
  fig.align = "center"
)

# Functions ----
opt.cut <- function(perf, pred){
    cut.ind = mapply(FUN=function(x, y, p){
        d = (x - 0)^2 + (y-1)^2
        ind = which(d == min(d))
        c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
            cutoff = p[[ind]])
    }, perf@x.values, perf@y.values, pred@cutoffs)
}

`%!in%` <- Negate(`%in%`)

p_fun <-
  function(object, newdata) {
    predict(object, newdata = newdata, type = "prob")[,2]
  }

# Load data from 0_get_and_tidy_data ----
tibble.oak_bleeding_model <-
  read_rds(path = path_wd(
    'empirical',
    '2_pipeline',
    '1_get_and_tidy_data',
    'out',
    'oak_bleeding_model',
    ext = 'rds'
  ))

# tibble.oak_bleeding_model_train <-
#   read_rds(path = path_wd(
#     'empirical',
#     '2_pipeline',
#     '1_get_and_tidy_data',
#     'out',
#     'oak_bleeding_model_train',
#     ext = 'rds'
#   ))
# 
# tibble.oak_bleeding_model_test <-
#   read_rds(path = path_wd(
#     'empirical',
#     '2_pipeline',
#     '1_get_and_tidy_data',
#     'out',
#     'oak_bleeding_model_test',
#     ext = 'rds'
#   ))

# Load Table 1 from 2_make_table_one ----
table.oak_bleeding_model <-
  read_rds(path = path_wd(
    'empirical',
    '2_pipeline',
    '2_make_table_one',
    'out',
    'oak_bleeding_model',
    ext = 'rds'
  ))

# Load helper for variable selection ----
helper.variable_selection <-
  read_rds(path = path_wd(
    'empirical',
    '2_pipeline',
    '0_create_helpers',
    'out',
    'ml_variable_selection',
    ext = 'rds'
  ))

# Create recipe for data preparation ----
recipe.bleeding_model <-
  recipe(
    formula = as.formula(glue("intraop_transfusion ~ ", paste(helper.variable_selection, collapse = "+"))),
    data = tibble.oak_bleeding_model
  ) %>%
  step_mutate_at(all_outcomes(), fn = as.numeric) %>%
  step_num2factor(all_outcomes(), transform = function(x) x + 1, levels = c("0", "1")) %>%
  step_corr(all_numeric()) %>%
  step_zv(all_predictors()) %>%
  # step_nzv(all_predictors()) %>%
  step_lincomb(all_numeric()) %>%
  # step_scale(all_numeric()) %>%
  prep()

# Bake the dataset ----
tibble.oak_bleeding_model_clean <-
  recipe.bleeding_model %>%
  bake(tibble.oak_bleeding_model)

## Create helper for partitioning ----
helper.training_test <-
  createDataPartition(
    tibble.oak_bleeding_model_clean$intraop_transfusion,
    p = 0.8,
    list = FALSE
  )

## Partition into training and test dataset ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_train", ext = "rds"))) {
  tibble.oak_bleeding_model_train <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_train", ext = "rds"))
} else {
  tibble.oak_bleeding_model_train <-
    tibble.oak_bleeding_model_clean %>%
    rownames_to_column() %>%
    filter(rowname %in% helper.training_test) %>%
    select(-rowname) %>%
    write_rds(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_train", ext = "rds"))
}

if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_test", ext = "rds"))) {
  tibble.oak_bleeding_model_test <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_test", ext = "rds"))
} else {
  tibble.oak_bleeding_model_test <-
    tibble.oak_bleeding_model_clean %>%
    rownames_to_column() %>%
    filter(rowname %!in% helper.training_test) %>%
    select(-rowname) %>%
    write_rds(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_test", ext = "rds"))
}

## Create separate vector for the outcome variable ----
helper.y_test <-
  tibble.oak_bleeding_model_test %>%
  modify_at(vars(intraop_transfusion), as.character) %>%
  modify_at(vars(intraop_transfusion), as.numeric) %>%
  pull(intraop_transfusion)

```

# Index

Welcome to the notebook!

## Table 1

```{r table_one,echo=FALSE}
table.oak_bleeding_model %>%
  knitr::kable()
```

# Prerequisites

## Formulas

  - Indexed blood volume^[Lemmens, H. J. M., Bernstein, D. P., & Brodsky, J. B. (2006). Estimating blood volume in obese and morbidly obese patients. Obesity Surgery, 16(6), 773â€“776. https://doi.org/10.1381/096089206777346673]: $BV_i = \frac{70}{\sqrt{\frac{BMI}{22}}}$^[$BV_i$ = Indexed blood volume, $BMI$ = Body mass index]
  - Estimated blood volume: $BV_e = BV_i \cdot Weight$^[$BV_e$ = Estimated blood volume]
  - Blood loss ratio: $BL_r = \frac{BV_e}{BL_a}$^[$BL_r$ = Blood loss ratio, $BL_a$ = Absolute blood loss]
  - Standardization method for age and bmi^[Iglewicz, B., & Hoaglin, D. C. (1993). How to detect and handle outliers. Milwaukee, Wis: ASQC Quality Press.]: $M_i = \frac{0.6745(x_i - \tilde(x))}{2 \cdot MAD}$^[$M_i$ = Modified Z-score, $\tilde(x)$ = Median of $x$, $MAD$ = Median absolute deviation]

# Results

## Data plots

```{r data_plots,echo=FALSE}
qqplot_bloodlossratio <-
  tibble.oak_bleeding_model %>%
  drop_na(blood_loss_ratio) %>%
  ggplot(aes(sample = blood_loss_ratio)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "Q-Q-Plot for blood loss ratio", subtitle = "Normal scale", x = "Theoretical quantiles", y = "Sample quantiles") +
  theme_light()

qqplot_logbloodlossratio <-
  tibble.oak_bleeding_model %>%
  drop_na(blood_loss_ratio) %>%
  ggplot(aes(sample = log(blood_loss_ratio))) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "Q-Q-Plot for blood loss ratio", subtitle = "Natural logarithm scale", x = "Theoretical quantiles", y = "Sample quantiles") +
  theme_light()

grid.arrange(qqplot_bloodlossratio, qqplot_logbloodlossratio, ncol = 2)

tibble.oak_bleeding_model %>%
drop_na(blood_loss_ratio) %>%
ggplot(aes(x = blood_loss_ratio)) +
geom_histogram(binwidth = 0.05) +
labs(title = "Histogram of blood loss ratio", x = "Blood loss ratio", y = "Count") +
theme_light()

tibble.oak_bleeding_model %>%
drop_na(intraop_transfusion) %>%
ggplot(aes(x = intraop_transfusion)) +
geom_bar() +
labs(title = "Bar chart of intraoperative transfusion", x = "Intraoperative transfusion", y = "Count") +
theme_light()
```

## Model outputs

### Models with intraoperative transfusion as response

#### Stepwise backwards logistic regression without interactions

```{r glm_stepwise,echo=FALSE}
helper.variables_names <-
  c(
    names(tibble.oak_bleeding_model_train),
    "I(age^2)"
  )

helper.glm_formula_full <-
  glue("intraop_transfusion ~ ", paste(c(helper.variables_names[!helper.variables_names %in% c("intraop_transfusion")]), collapse = " + "))

model.glm.intraoptransfusion_full <-
  glm(
    formula = helper.glm_formula_full,
    data = tibble.oak_bleeding_model_train,
    family = binomial()
  ) %>%
  MASS::stepAIC(scope = list(upper = helper.glm_formula_full, lower = ~ 1), trace = FALSE) %>%
  write_rds(
    path = path_wd("paper", "notebook", "notebook_files", "models", "model.glm_intraoptransfusion_full", ext = "rds")
  )

model.glm.intraoptransfusion_full_scaled <-
  update(
    model.glm.intraoptransfusion_full,
    formula. = ~ . - blood_loss_ratio + I(blood_loss_ratio * 100) - preop_hb + I(preop_hb * 10)
  ) %>%
  write_rds(
    path = path_wd("paper", "notebook", "notebook_files", "models", "model.glm_intraoptransfusion_full_scaled", ext = "rds")
  )

summary(model.glm.intraoptransfusion_full)

summary(model.glm.intraoptransfusion_full_scaled)

```

<!-- ##### ROC-AUC for the test dataset -->

```{r glm_full_rocauc,echo=FALSE}
# tibble.glm_full_rocauc <-
#   tibble(
#     predictions = predict(model.glm.intraoptransfusion_model_full, newdata = tibble.oak_bleeding_model_test, type = "response"),
#     labels = pluck(tibble.oak_bleeding_model_test, "intraop_transfusion")
#   )
# 
# prediction.glm_full <-
#   prediction(
#     predictions = pluck(tibble.glm_full_rocauc, "predictions"),
#     labels = pluck(tibble.glm_full_rocauc, "labels")
#   )
# 
# auc.glm_full <-
#   performance(
#     prediction.glm_full,
#     measure = "auc"
#   )
# 
# cat(glue("AUC: ", auc.glm_full@y.values[[1]], "\n"))
# 
# roc.glm_full <-
#   performance(
#     prediction.glm_full,
#     measure = "tpr",
#     x.measure = "fpr"
#   )
# 
# plot(
#   roc.glm_full,
#   main = "ROC-AUC"
# )
# abline(a=0, b= 1)
# 
# cat("Optimal cut-off point:\n")
# opt.cut(roc.glm_full, prediction.glm_full) %>%
#   as_tibble_row(.name_repair = "unique") %>%
#   rename(Sensitivity = `...1`, Specificity = `...2`, `Cut-Off` = `...3`) %>%
#   knitr::kable()

```

#### Stepwise backwards logistic regression with interactions

```{r glm_stepwise_inter,echo=FALSE}
helper.variables_significant_filter <-
  c(
    "I(blood_loss_ratio * 100)",
    "oak",
    "tcaggr",
    "norepinephrine",
    "p_tumor",
    "I(preop_hb * 10)",
    "I(age^2)"
  )

helper.glm_formula_reduced_interactions <-
  glue("intraop_transfusion ~ (", paste(helper.variables_significant_filter, collapse = " + "), ") ^ 2")

model.glm.intraoptransfusion_reduced_interactions <-
  glm(
    formula = helper.glm_formula_reduced_interactions,
    data = tibble.oak_bleeding_model_train,
    family = binomial()
  ) %>%
  MASS::stepAIC(scope = list(upper = helper.glm_formula_reduced_interactions, lower = ~ 1), trace = FALSE)

summary(model.glm.intraoptransfusion_reduced_interactions)

```

<!-- ##### ROC-AUC for the test dataset -->

```{r glm_inter_rocauc,echo=FALSE}
# tibble.glm_inter_rocauc <-
#   tibble(
#     predictions = predict(model.glm.intraoptransfusion_model_reduced_interactions, newdata = tibble.oak_bleeding_model_test, type = "response"),
#     labels = pluck(tibble.oak_bleeding_model_test, "intraop_transfusion")
#   )
# 
# prediction.glm_inter <-
#   prediction(
#     predictions = pluck(tibble.glm_inter_rocauc, "predictions"),
#     labels = pluck(tibble.glm_inter_rocauc, "labels")
#   )
# 
# auc.glm_inter <-
#   performance(
#     prediction.glm_inter,
#     measure = "auc"
#   )
# 
# cat(glue("AUC: ", auc.glm_inter@y.values[[1]], "\n"))
# 
# roc.glm_inter <-
#   performance(
#     prediction.glm_inter,
#     measure = "tpr",
#     x.measure = "fpr"
#   )
# 
# plot(
#   roc.glm_inter,
#   main = "ROC-AUC"
# )
# abline(a=0, b= 1)
# 
# cat("Optimal cut-off point:\n")
# opt.cut(roc.glm_inter, prediction.glm_inter) %>%
#   as_tibble_row(.name_repair = "unique") %>%
#   rename(Sensitivity = `...1`, Specificity = `...2`, `Cut-Off` = `...3`) %>%
#   knitr::kable()

```

#### Machine learning classification

```{r ml_train,echo=FALSE}
## Create helper for training control parameters ----
helper.trainControl_rf <-
  trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    returnData = FALSE,
    classProbs = TRUE,
    summaryFunction = twoClassSummary
  )

helper.trainControl_glm <-
  trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    returnData = FALSE,
    classProbs = TRUE,
    summaryFunction = twoClassSummary
  )

helper.trainControl_svm <-
  trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    returnData = FALSE,
    classProbs = TRUE,
    summaryFunction = twoClassSummary
  )

helper.trainControl_xgb <-
  trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    allowParallel = TRUE,
    returnData = FALSE, 
    classProbs = TRUE,
    summaryFunction = twoClassSummary
  )

## Fit classification models ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_rf", ext = "rds"))) {
  model.classif_rf <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_rf", ext = "rds"))
} else {
  model.classif_rf <-
    train(
      make.names(intraop_transfusion) ~ . ,
      data = tibble.oak_bleeding_model_train,
      method="rf",
      preProcess = c("center", "scale"),
      ntree = 100,
      tuneLength = 10,
      trControl = helper.trainControl_rf,
      metric = "ROC"
    ) %>%
    write_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_rf", ext = "rds"))
}

if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_glm", ext = "rds"))) {
  model.classif_glm <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_glm", ext = "rds"))
} else {
  model.classif_glm <-
    train(
      make.names(intraop_transfusion) ~ . + I(age^2),
      data = tibble.oak_bleeding_model_train,
      method = "glmnet",
      preProcess = c("center", "scale"),
      family = "binomial",
      tuneLength = 25,
      trControl = helper.trainControl_glm,
      metric = "ROC"
    ) %>%
    write_rds(
      path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_glm", ext = "rds")
    )
}

if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_svm", ext = "rds"))) {
  model.classif_svm <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_svm", ext = "rds"))
} else {
  model.classif_svm <-
    train(
      make.names(intraop_transfusion) ~ . ,
      data = tibble.oak_bleeding_model_train,
      method="svmRadial",
      preProcess = c("center", "scale"),
      prob.model = TRUE,
      tuneLength = 10,
      trControl = helper.trainControl_svm,
      metric = "ROC"
    ) %>%
    write_rds(
      path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_svm", ext = "rds")
    )
}

if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_xgb", ext = "rds"))) {
  model.classif_xgb <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_xgb", ext = "rds"))
} else {
  model.classif_xgb <-
    train(
      make.names(intraop_transfusion) ~ . ,
      data = tibble.oak_bleeding_model_train,
      method="xgbTree",
      preProcess = c("center", "scale"),
      tuneLength = 10,
      trControl = helper.trainControl_xgb,
      metric = "ROC"
    ) %>%
    write_rds(
      path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_xgb", ext = "rds")
    )
}
```

#### Model performance

```{r model_performance,echo=FALSE}

## Create explainers ----
explainer.model_glm <-
  explain(
    model.glm.intraoptransfusion_full_scaled,
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = function(object, newdata) {
      predict(object, newdata = newdata, type = "response")
    }
  )

explainer.classif_rf <-
  explain(
    model.classif_rf,
    label = "Random Forest",
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = p_fun
  )

explainer.classif_glm <-
  explain(
    model.classif_glm,
    label = "Elastic Net Logistic Regression",
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = p_fun
  )

explainer.classif_svm <-
  explain(
    model.classif_svm,
    label = "Support Vector Machine",
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = p_fun
  )

explainer.classif_xgb <-
  explain(
    model.classif_xgb,
    label = "eXtreme Gradient Boosting",
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = p_fun
  )

## Create model performance objects ----
mp.model_glm <-
  model_performance(explainer.model_glm)

mp.classif_rf <-
  model_performance(explainer.classif_rf)

mp.classif_glm <-
  model_performance(explainer.classif_glm)

mp.classif_svm <-
  model_performance(explainer.classif_svm)

mp.classif_xgb <-
  model_performance(explainer.classif_xgb)

## Create variable importance objects ----
vi.model_glm <-
  variable_importance(
    explainer.model_glm,
    loss_function = loss_one_minus_auc,
    label = "Logistic Regression",
    type = "difference"
  )

vi.classif_rf <-
  variable_importance(
    explainer.classif_rf,
    loss_function = loss_one_minus_auc,
    label = "Random Forest",
    type = "difference"
  )

vi.classif_glm <-
  variable_importance(
    explainer.classif_glm,
    loss_function = loss_one_minus_auc,
    label = "Elastic Net Logistic Regression",
    type = "difference"
  )

vi.classif_svm <-
  variable_importance(
    explainer.classif_svm,
    loss_function = loss_one_minus_auc,
    label = "Support Vector Machine",
    type = "difference"
  )

vi.classif_xgb <-
  variable_importance(
    explainer.classif_xgb,
    loss_function = loss_one_minus_auc,
    label = "eXtreme Gradient Boosting",
    type = "difference"
  )

list(
  mp.model_glm,
  mp.classif_xgb,
  mp.classif_glm,
  mp.classif_rf,
  mp.classif_svm
) %>%
map_dfr(pluck, "measures") %>%
add_column(
  tibble(
    name = c(
      "Logistic Regression",
      "eXtreme Gradient Boosting",
      "Elastic Net Logistic Regression",
      "Random Forest",
      "Support Vector Machine"
    )
  ),
  .before = 1
) %>%
arrange(desc(auc)) %>%
modify_at(vars(recall, precision, f1, accuracy, auc), round, 2) %>%
knitr::kable()

```

#### Feature importance

```{r ml_importance,echo=FALSE}

plot(
  vi.model_glm,
  vi.classif_xgb,
  vi.classif_glm,
  vi.classif_rf,
  vi.classif_svm
)

```