---
title: "R Notebook for the cystectomy study"
author: "Pascal Jerney"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::gitbook:
    config:
      toc:
        collapse: subsection
        scroll_highlight: yes
        before: null
        after: null
      toolbar:
        position: fixed
      edit : null
      download:
        - ["notebook.pdf", "PDF"]
      search: yes
      fontsettings:
        theme: white
        family: sans
        size: 2
      sharing:
        facebook: yes
        github: no
        twitter: yes
        linkedin: no
        weibo: no
        instapaper: no
        vk: no
        all: ['facebook', 'twitter', 'linkedin', 'weibo', 'instapaper']
      info: yes
  bookdown::word_document2: default
  bookdown::pdf_document2:
    toc: false
    keep_tex: true
    latex_engine: xelatex
  html_notebook: default
---

```{r setup, echo=FALSE}

# Set Random Number Generator Seed
set.seed(34567)

# Load packages ----
if (!require("pacman")) {
  install.packages("pacman")
}
pacman::p_load(
  "tidyverse",
  "conflicted",
  "rprojroot",
  "fs",
  "tableone",
  "modelr",
  "glue",
  "gridExtra",
  "pander",
  "htmltools",
  "MASS",
  "car",
  "recipes",
  "ROCR",
  "DALEX",
  "DALEXtra",
  "tidymodels",
  "probably",
  "ModelMetrics",
  "emmeans",
  "sjPlot",
  "easystats",
  "DescTools",
  "givitiR",
  "slider"
)
pacman::p_unload("MASS")

# Set working directory ----
setwd(rprojroot::find_rstudio_root_file())
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

# Set general options ----
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png",
  dpi = 300,
  fig.asp = 0.8,
  fig.width = 10,
  out.width = "100%",
  fig.align = "center"
)

# Preferred function names ----
conflict_prefer("select", "dplyr")
conflict_prefer("model_performance", "DALEX")
conflict_prefer("collapse", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("explain", "DALEX")
conflict_prefer("spec", "yardstick")
conflict_prefer("sens", "yardstick")

# Use second level from outcome factors for GLM compliance ----
# (deprecated, will be removed in future!)
options(yardstick.event_first = FALSE)

source(path_wd("..", "Common", "my_brier_metric", ext = "R"))

# Functions ----
`%!in%` <- Negate(`%in%`)

# Load data from 0_get_and_tidy_data ----
tibble.transfusion <-
  read_rds(file = path_wd(
    'empirical',
    '2_pipeline',
    '1_get_and_tidy_data',
    'out',
    'oak_bleeding_model',
    ext = 'rds'
  ))

# Create helper for Table 1 ----
helper.tableone <- c(
  "blood_loss_ml",
  "blood_loss_ratio",
  "oak",
  "tcaggr",
  "preop_hb",
  "preop_tc",
  "bmi",
  "age",
  "cci_5plus",
  "gender",
  "p_tumor",
  "p_node_pos",
  # "op_year",
  "op_duration_min",
  "previous_op",
  "norepinephrine",
  "crystalloids_mlkgh",
  "neoadj_chemo"
)

# Create Table 1 ----
table.transfusion <-
  tibble.transfusion %>%
  CreateTableOne(
    vars = helper.tableone,
    strata = c("intraop_transfusion"),
    data = .,
    test = TRUE
  ) %>%
  print(., nonnormal = c(
    "blood_loss_ml",
    "blood_loss_ratio",
    "preop_hb",
    "preop_tc",
    "bmi",
    "age",
    "op_duration_min",
    "crystalloids_mlkgh"
  ), printToggle = FALSE, noSpaces = TRUE)

# Create variable name helper for model formula generation ----
helper.variable_names <- c(
  "blood_loss_ratio",
  "oak",
  # "tcaggr",
  "preop_hb",
  "preop_tc",
  "bmi",
  "age",
  "cci_5plus",
  "gender",
  "p_tumor",
  "p_node_pos",
  "op_duration_min",
  "previous_op",
  "norepinephrine",
  "crystalloids_mlkgh",
  "neoadj_chemo"
  # "op_year"
)

tibble.transfusion <-
  tibble.transfusion %>%
  select(intraop_transfusion, all_of(helper.variable_names))

# Create new counterfactual observations for predictions ----
tibble.transfusion_cf <-
  tibble.transfusion %>%
  slice_sample(n = 0) %>%
  select(-intraop_transfusion) %>%
  add_row(
    expand_grid(
      blood_loss_ratio = c(0.1, 0.4),
      preop_hb = c(104, 137),
      age = c(52, 80)
    ),
    gender = "female",
    p_tumor = "3",
    norepinephrine = "yes",
    oak = "no",
    op_duration_min = 386
  ) %>%
  add_row(
    expand_grid(
      blood_loss_ratio = c(0.1, 0.4),
      preop_hb = c(113, 152),
      age = c(57, 79)
    ),
    gender = "male",
    p_tumor = "3",
    norepinephrine = "yes",
    oak = "no",
    op_duration_min = 393
  )

# Create formula helper for models ----
helper.model_formula <-
  as.formula(
    glue(
      "intraop_transfusion ~ ",
      paste(c(helper.variable_names[!helper.variable_names %in% c("intraop_transfusion")]), collapse = " + ")
    )
  )

# Create data frames for training/test sets ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.transfusion_train", ext = "rds")) & file_exists(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.transfusion_test", ext = "rds"))) {
  helper.data_split <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "data", "helper.data_split", ext = "rds"))
  tibble.transfusion_train <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "data", "tibble.transfusion_train", ext = "rds"))
  tibble.transfusion_test <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "data", "tibble.transfusion_test", ext = "rds"))
} else {
  helper.data_split <-
    initial_split(tibble.transfusion, prop = 9/10, strata = intraop_transfusion) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "data", "helper.data_split", ext = "rds"))
  tibble.transfusion_train <-
    training(helper.data_split) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "data", "tibble.transfusion_train", ext = "rds"))
  tibble.transfusion_test <-
    testing(helper.data_split) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "data", "tibble.transfusion_test", ext = "rds"))
}

# Create cross-validation folds ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "data", "helper.training_folds", ext = "rds"))) {
  helper.training_folds <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "data", "helper.training_folds", ext = "rds"))
} else {
  helper.training_folds <-
    vfold_cv(tibble.transfusion_train, v = 10, repeats = 10, strata = intraop_transfusion) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "data", "helper.training_folds", ext = "rds"))
}

# Create metric helper
helper.multi_metric <-
  metric_set(accuracy, sens, spec, roc_auc, my_brier)

# Remnant
#     modify_at(vars(cci_5plus), `contrasts<-`, value = MASS::contr.sdif(6)) %>%
#     modify_at(vars(p_tumor), `contrasts<-`, value = MASS::contr.sdif(5)) %>%

# Create separate vector for the outcome variable ----
helper.y_test <-
  tibble.transfusion_test %>%
  # modify_at(vars(intraop_transfusion), as.character) %>%
  modify_at(vars(intraop_transfusion), as.numeric) %>%
  mutate(intraop_transfusion = intraop_transfusion - 1) %>%
  pull(intraop_transfusion)

# Create separate vector for the outcome variable ----
helper.y_train <-
  tibble.transfusion_train %>%
  # modify_at(vars(intraop_transfusion), as.character) %>%
  modify_at(vars(intraop_transfusion), as.numeric) %>%
  mutate(intraop_transfusion = intraop_transfusion - 1) %>%
  pull(intraop_transfusion)



```

# Index

Welcome to the notebook!

## Table 1

```{r table_one,echo=FALSE}

# Print Table 1 ----
table.transfusion %>%
  knitr::kable()

```

# Prerequisites

## Formulas

  - Indexed blood volume^[Lemmens, H. J. M., Bernstein, D. P., & Brodsky, J. B. (2006). Estimating blood volume in obese and morbidly obese patients. Obesity Surgery, 16(6), 773â€“776. https://doi.org/10.1381/096089206777346673]: $BV_i = \frac{70}{\sqrt{\frac{BMI}{22}}}$^[$BV_i$ = Indexed blood volume, $BMI$ = Body mass index]
  - Estimated blood volume: $BV_e = BV_i \cdot Weight$^[$BV_e$ = Estimated blood volume]
  - Blood loss ratio: $BL_r = \frac{BV_e}{BL_a}$^[$BL_r$ = Blood loss ratio, $BL_a$ = Absolute blood loss]
  - Standardization method for age and bmi^[Iglewicz, B., & Hoaglin, D. C. (1993). How to detect and handle outliers. Milwaukee, Wis: ASQC Quality Press.]: $M_i = \frac{0.6745(x_i - \tilde(x))}{2 \cdot MAD}$^[$M_i$ = Modified Z-score, $\tilde(x)$ = Median of $x$, $MAD$ = Median absolute deviation]

# Results

## Data plots

```{r data_plots,echo=FALSE}

# Print QQ plots ----
qqplot_bloodlossratio <-
  tibble.transfusion %>%
  drop_na(blood_loss_ratio) %>%
  ggplot(aes(sample = blood_loss_ratio)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "Q-Q-Plot for blood loss ratio", subtitle = "Normal scale", x = "Theoretical quantiles", y = "Sample quantiles") +
  theme_light()

qqplot_logbloodlossratio <-
  tibble.transfusion %>%
  drop_na(blood_loss_ratio) %>%
  ggplot(aes(sample = log(blood_loss_ratio))) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "Q-Q-Plot for blood loss ratio", subtitle = "Natural logarithm scale", x = "Theoretical quantiles", y = "Sample quantiles") +
  theme_light()

grid.arrange(qqplot_bloodlossratio, qqplot_logbloodlossratio, ncol = 2)

# Print histogram of blood_loss_ratio ----
tibble.transfusion %>%
drop_na(blood_loss_ratio) %>%
ggplot(aes(x = blood_loss_ratio)) +
geom_histogram(binwidth = 0.05) +
labs(title = "Histogram of blood loss ratio", x = "Blood loss ratio", y = "Count") +
theme_light()

# Print bar chart of intraop_transfusion ----
tibble.transfusion %>%
drop_na(intraop_transfusion) %>%
ggplot(aes(x = intraop_transfusion)) +
geom_bar() +
labs(title = "Bar chart of intraoperative transfusion", x = "Intraoperative transfusion", y = "Count") +
theme_light()
```

## Model outputs

### Models with intraoperative transfusion as response

#### Stepwise Logistic Regression

```{r glm_stepwise, echo=FALSE}

# Create recipe for data preparation ----
recipe.glm_raw <-
  recipe(
    formula = intraop_transfusion ~ .,
    data = tibble.transfusion_train
  ) %>%
  # step_relevel(all_outcomes(), ref_level = "no") %>%
  # step_rm(-any_of(helper.variable_names), -all_outcomes()) %>%
  step_corr(all_numeric()) %>%
  step_dummy("gender") %>%
  step_zv(all_predictors()) %>%
  # step_nzv(all_predictors()) %>%
  step_lincomb(all_numeric()) %>%
  step_normalize(all_numeric()) %>%
  step_interact(~ (blood_loss_ratio + preop_hb + age + gender_female)^2)

tibble.transfusion_train_glm_raw <-
  recipe.glm_raw %>%
  prep(training = tibble.transfusion_train) %>%
  juice()

fit.glm_raw <-
  glm(
    intraop_transfusion ~ .,
    data = tibble.transfusion_train_glm_raw,
    family = binomial()
  )

# fit.glm_noyear_raw <-
#   fit.glm_raw %>%
#   update(
#     formula. = . ~ . - op_year
#   )

# Create stepwise regression
fit.glmstep_raw <-
  MASS::stepAIC(
    fit.glm_raw,
    scope = list(
      upper = ~ .,
      lower = ~ 1
    ),
    direction = "both",
    trace = FALSE
  )

# fit.glmstep_noyear_raw <-
#   MASS::stepAIC(
#     fit.glm_noyear_raw,
#     scope = list(
#       upper = ~ .,
#       lower = ~ 1
#     ),
#     direction = "both",
#     trace = FALSE
#   )

helper.variable_names_reduced <-
  names(attr(fit.glmstep_raw$terms, "dataClasses")[-1])

# helper.noyear_variable_names_reduced <-
#   names(attr(fit.glmstep_noyear_raw$terms, "dataClasses")[-1])

# Create recipe for data preparation ----
recipe.glm <-
  recipe.glm_raw %>%
  step_rm(-any_of(helper.variable_names_reduced), -"gender_female", -all_outcomes()) # %>%

# recipe.glm_noyear <-
#   recipe.glm_raw %>%
#   step_rm(-any_of(helper.noyear_variable_names_reduced), -"gender_female", -all_outcomes()) # %>%

model.glm <-
  logistic_reg() %>%
  set_engine("glm")

# model.glm_noyear <-
#   logistic_reg() %>%
#   set_engine("glm")

workflow.glm <-
  workflow() %>%
  add_recipe(recipe.glm) %>%
  add_model(model.glm)

# workflow.glm_noyear <-
#   workflow() %>%
#   add_recipe(recipe.glm_noyear) %>%
#   add_model(model.glm_noyear)

fit.glm <-
  workflow.glm %>%
  fit(data = tibble.transfusion_train)

# fit.glm_noyear <-
#   workflow.glm_noyear %>%
#   fit(data = tibble.transfusion_train)

# Create cross-validation resamples ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "resamples.glm", ext = "rds"))) {
  resamples.glm <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.glm", ext = "rds"))
} else {
  resamples.glm <-
    workflow.glm %>%
    fit_resamples(
      helper.training_folds,
      metrics = helper.multi_metric,
      control = control_resamples(
        save_pred = TRUE,
        event_level = "second"
      )
    ) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.glm", ext = "rds"))
}

# if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "resamples.glm_noyear", ext = "rds"))) {
#   resamples.glm_noyear <-
#     read_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.glm_noyear", ext = "rds"))
# } else {
#   resamples.glm_noyear <-
#     workflow.glm_noyear %>%
#     fit_resamples(
#       helper.training_folds,
#       metrics = helper.multi_metric,
#       control = control_resamples(
#         save_pred = TRUE,
#         event_level = "second"
#       )
#     ) %>%
#     write_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.glm_noyear", ext = "rds"))
# }

# Calculate resampled metrics
rsmetrics.glm <-
  resamples.glm %>%
  collect_predictions() %>%
  group_by(id, id2) %>%
  helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second") %>%
  group_by(.metric) %>%
  summarise(.estimate = mean(.estimate), .groups = "drop_last")

# rsmetrics.glm_noyear <-
#   resamples.glm_noyear %>%
#   collect_predictions() %>%
#   group_by(id, id2) %>%
#   helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second") %>%
#   group_by(.metric) %>%
#   summarise(.estimate = mean(.estimate), .groups = "drop_last")

# Calculate optimal thresholds resample-wise and average the results ----
thresholds.glm <-
  resamples.glm %>%
  collect_predictions(summarize = FALSE) %>%
  group_by(id, id2) %>%
  threshold_perf(
    truth = intraop_transfusion,
    estimate = .pred_yes,
    thresholds = seq(0, 1, by = 0.01)
  ) %>% 
  filter(.metric %in% c("spec", "sens", "distance")) %>%
  spread(.metric, .estimate) %>%
  mutate(distance_abs = abs(sens - spec)) %>%
  group_by(id, id2) %>%
  filter(distance_abs == min(distance_abs)) %>%
  ungroup() %>%
  summarise(
    .threshold = mean(.threshold),
    distance = mean(distance),
    sens = mean(sens),
    spec = mean(spec),
    distance_abs = mean(distance_abs)
  )

# thresholds.glm_noyear <-
#   resamples.glm_noyear %>%
#   collect_predictions(summarize = FALSE) %>%
#   group_by(id, id2) %>%
#   threshold_perf(
#     truth = intraop_transfusion,
#     estimate = .pred_yes,
#     thresholds = seq(0, 1, by = 0.01)
#   ) %>% 
#   filter(.metric %in% c("spec", "sens", "distance")) %>%
#   spread(.metric, .estimate) %>%
#   mutate(distance_abs = abs(sens - spec)) %>%
#   group_by(id, id2) %>%
#   filter(distance_abs == min(distance_abs)) %>%
#   ungroup() %>%
#   summarise(
#     .threshold = mean(.threshold),
#     distance = mean(distance),
#     sens = mean(sens),
#     spec = mean(spec),
#     distance_abs = mean(distance_abs)
#   )

# Create reduced test dataset
# tibble.transfusion_test_reduced <-
#   recipe.glm %>%
#   prep(training = tibble.transfusion_test) %>%
#   juice()

# Calculate test set metrics
testmetrics.glm <-
  predict(fit.glm, tibble.transfusion_test, type = "prob") %>%
  bind_cols(predict(fit.glm, tibble.transfusion_test)) %>%
  bind_cols(tibble.transfusion_test %>% select(intraop_transfusion)) %>%
  helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second")

# testmetrics.glm_noyear <-
#   predict(fit.glm_noyear, tibble.transfusion_test, type = "prob") %>%
#   bind_cols(predict(fit.glm_noyear, tibble.transfusion_test)) %>%
#   bind_cols(tibble.transfusion_test %>% select(intraop_transfusion)) %>%
#   helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second")

# Create explainer ----
explainer.glm <-
  explain_tidymodels(
    fit.glm,
    label = "Stepwise Logistic Regression",
    data = tibble.transfusion_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    type = "classification"
  )

# explainer.glm_noyear <-
#   explain_tidymodels(
#     fit.glm_noyear,
#     label = "Stepwise Logistic Regression",
#     data = tibble.transfusion_test %>% select(-intraop_transfusion),
#     y = helper.y_test,
#     type = "classification"
#   )

# Create model performance object ----
mp.glm <-
  model_performance(explainer.glm, cutoff = pluck(thresholds.glm, ".threshold"))

# mp.glm_noyear <-
#   model_performance(explainer.glm_noyear, cutoff = pluck(thresholds.glm_noyear, ".threshold"))

# Create variable importance object ----
vi.glm <-
  feature_importance(
    explainer.glm,
    loss_function = loss_one_minus_auc,
    label = "Stepwise Logistic Regression",
    type = "difference",
    N = NULL # use whole dataset
  )

# vi.glm_noyear <-
#   feature_importance(
#     explainer.glm_noyear,
#     loss_function = loss_one_minus_auc,
#     label = "Stepwise Logistic Regression",
#     type = "difference",
#     N = NULL # use whole dataset
#   )

# Create counterfactual data grid ----
tibble.transfusion_cf_grid <-
  recipe.glm_raw %>%
  prep(training = tibble.transfusion) %>%
  juice() %>%
  group_by(gender_female) %>%
  data_grid(
    age = seq_range(age, n = 9, trim = 0.3173),
    preop_hb = seq_range(preop_hb, n = 9, trim = 0.3173),
    blood_loss_ratio = seq(0, 0.5, by = 0.1),
    p_tumor = "3",
    # op_year = "2016",
    # .model = fit.glm_raw
    .model = fit.glm %>% pull_workflow_fit() %>% chuck("fit")
  )


```

##### Coefficients

```{r ml_glm_coef_plot,echo=FALSE}

plot_model(
  fit.glm %>% pull_workflow_fit() %>% pluck("fit"),
  sort.est = TRUE,
  title = "Odds ratios",
  show.values = TRUE,
  value.offset = 0.2,
  digits = 3,
  vline.color = "black"
) +
theme_ema()

# plot_model(
#   fit.glm_noyear %>% pull_workflow_fit() %>% pluck("fit"),
#   sort.est = TRUE,
#   title = "Odds ratios",
#   show.values = TRUE,
#   value.offset = 0.2,
#   digits = 3,
#   vline.color = "black"
# ) +
# theme_ema()

```

```{r ml_glm_summary,echo=FALSE}

fit.glm %>%
  tidy(exponentiate = TRUE, conf.int = TRUE) %>%
  mutate_if(is.numeric, round, 4) %>%
  knitr::kable()

# fit.glm_noyear %>%
#   tidy(exponentiate = TRUE, conf.int = TRUE) %>%
#   mutate_if(is.numeric, round, 4) %>%
#   knitr::kable()

```

##### Estimated marginal means

```{r ml_glm_emmeans,echo=FALSE}

fit.glm %>%
  pull_workflow_fit() %>%
  pluck("fit") %>%
  emmeans(
    trt.vs.ctrl ~ p_tumor,
    data = fit.glm %>% pull_workflow_prepped_recipe() %>% bake(new_data = tibble.transfusion_train),
    options = list(type = "response", adjust = "mvt")
  ) %>%
  pluck("contrasts") %>%
  tidy() %>% 
  mutate_if(is.numeric, round, 4) %>%
  knitr::kable()

fit.glm %>%
  pull_workflow_fit() %>%
  pluck("fit") %>%
  emmeans(
    consec ~ p_tumor,
    data = fit.glm %>% pull_workflow_prepped_recipe() %>% bake(new_data = tibble.transfusion_train),
    options = list(type = "response", adjust = "mvt")
  ) %>%
  pluck("contrasts") %>%
  tidy() %>% 
  mutate_if(is.numeric, round, 4) %>%
  knitr::kable()

fit.glm %>%
  pull_workflow_fit() %>%
  pluck("fit") %>%
  emmeans(
    mean_chg ~ p_tumor,
    data = fit.glm %>% pull_workflow_prepped_recipe() %>% bake(new_data = tibble.transfusion_train),
    options = list(type = "response", adjust = "mvt")
  ) %>%
  pluck("contrasts") %>%
  tidy() %>% 
  mutate_if(is.numeric, round, 4) %>%
  knitr::kable()

# fit.glm %>%
#   pull_workflow_fit() %>%
#   pluck("fit") %>%
#   emmeans(
#     consec ~ op_year,
#     data = fit.glm %>% pull_workflow_prepped_recipe() %>% bake(new_data = tibble.transfusion_train),
#     options = list(type = "response", adjust = "mvt")
#   ) %>%
#   pluck("contrasts") %>%
#   tidy() %>% 
#   mutate_if(is.numeric, round, 4) %>%
#   knitr::kable()
# 
# fit.glm %>%
#   pull_workflow_fit() %>%
#   pluck("fit") %>%
#   emmeans(
#     mean_chg ~ op_year,
#     data = fit.glm %>% pull_workflow_prepped_recipe() %>% bake(new_data = tibble.transfusion_train),
#     options = list(type = "response", adjust = "mvt")
#   ) %>%
#   pluck("contrasts") %>%
#   tidy() %>% 
#   mutate_if(is.numeric, round, 4) %>%
#   knitr::kable()

```

##### Binned residuals

```{r ml_glm_binnedresiduals,echo=FALSE}

fit.glm %>%
  pull_workflow_fit() %>%
  pluck("fit") %>%
  binned_residuals(n_bins = 20)

# fit.glm_noyear %>%
#   pull_workflow_fit() %>%
#   pluck("fit") %>%
#   binned_residuals(n_bins = 32)

```

##### Variance inflation factor

```{r ml_glm_vif,echo=FALSE}

fit.glm %>%
  pull_workflow_fit() %>%
  pluck("fit") %>%
  vif()

# fit.glm_noyear %>%
#   pull_workflow_fit() %>%
#   pluck("fit") %>%
#   vif()

```

##### Hosmer

```{r ml_glm_hosmer,echo=FALSE}

# Create helpers for le Cessie-van Houwelingen-Copas-Hosmer unweighted sum of squares test for global goodness of fit ----
# helper.glm_noyear_datamatrix <-
#   fit.glm_noyear %>%
#   pull_workflow_fit() %>%
#   pluck("fit", "data") %>%
#   modify_if(is.factor, ~ as.numeric(.x) - 1) %>%
#   data.matrix()

helper.glm_datamatrix <-
  fit.glm %>%
  pull_workflow_fit() %>%
  pluck("fit", "data") %>%
  modify_if(is.factor, ~ as.numeric(.x) - 1) %>%
  data.matrix()

# hosmer.glm_noyear <-
#   HosmerLemeshowTest(
#     fit = fit.glm_noyear %>%
#       pull_workflow_fit() %>%
#       pluck("fit", "fitted.values"),
#     obs = helper.glm_noyear_datamatrix[,"..y"],
#     X = helper.glm_noyear_datamatrix[, colnames(helper.glm_noyear_datamatrix) != "..y"]
#   )

(hosmer.glm <-
  HosmerLemeshowTest(
    fit = fit.glm %>%
      pull_workflow_fit() %>%
      pluck("fit", "fitted.values"),
    obs = helper.glm_datamatrix[,"..y"],
    X = helper.glm_datamatrix[, colnames(helper.glm_datamatrix) != "..y"]
  )
)


```

#### Calibration plot

```{r ml_glm_calibration,echo=FALSE}

cb.glm_internal <-
  givitiCalibrationBelt(
    o = helper.y_train,
    e = predict(fit.glm, tibble.transfusion_train, type = "prob") %>% pull(.pred_yes),
    devel = "internal"
  )

cb.glm_external <-
  givitiCalibrationBelt(
    o = helper.y_test,
    e = predict(fit.glm, tibble.transfusion_test, type = "prob") %>% pull(.pred_yes),
    devel = "external"
  )

plot(cb.glm_internal, main = "CysTrans internal calibration",
                          xlab = "CysTrans predicted probability",
                          ylab = "Observed transfusion")

plot(cb.glm_external, main = "CysTrans external calibration",
                          xlab = "CysTrans predicted probability",
                          ylab = "Observed transfusion")

```

#### Counterfactual predictions

```{r ml_glm_cf_preds, echo=FALSE}

(helper.cf_plot_list <-
  slide(
    tibble.transfusion_cf,
    ~ predict_parts(explainer = explainer.glm, new_observation = .x, type = "break_down", interactions = TRUE)
  ) %>%
  map(plot, max_features = 12, interactions = TRUE)
)

# grid.arrange(grobs = helper.cf_plot_list, ncol = 2)

```

#### Elastic Net Logistic Regression

```{r ml_elasticnet, eval=FALSE, include=FALSE}

# Create recipe for data preparation ----
recipe.glmnet <-
  recipe(
    formula = intraop_transfusion ~ .,
    data = tibble.transfusion_train
  ) %>%
  # step_relevel(all_outcomes(), ref_level = "no") %>% # , skip = TRUE
  step_rm(-any_of(helper.variable_names), -all_outcomes()) %>%
  step_corr(all_numeric()) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_predictors()) %>%
  # step_nzv(all_predictors()) %>%
  step_lincomb(all_numeric()) %>%
  step_normalize(all_numeric()) # %>%

model.glmnet <-
  logistic_reg(penalty = tune(), mixture = tune()) %>%
  set_engine("glmnet")

workflow.glmnet <-
  workflow() %>%
  add_recipe(recipe.glmnet) %>%
  add_model(model.glmnet)

if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "tune.glmnet", ext = "rds"))) {
  tune.glmnet <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "tune.glmnet", ext = "rds"))
} else {
  tune.glmnet <-
    workflow.glmnet %>%
    tune_grid(
      resamples = helper.training_folds,
      grid = grid_regular(penalty(), mixture(), levels = 11),
      control = control_grid(save_pred = TRUE, event_level = "second"),
      metrics = helper.multi_metric
    ) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "tune.glmnet", ext = "rds"))
}

besttune.glmnet <-
  tune.glmnet %>%
  select_best(metric = "roc_auc")

finalwf.glmnet <-
  workflow.glmnet %>%
  finalize_workflow(besttune.glmnet)

fit.glmnet <-
  finalwf.glmnet %>%
  fit(data = tibble.transfusion_train)

# Create cross-validation resamples ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "resamples.glmnet", ext = "rds"))) {
  resamples.glmnet <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.glmnet", ext = "rds"))
} else {
  resamples.glmnet <-
    finalwf.glmnet %>%
    fit_resamples(
      helper.training_folds,
      metrics = helper.multi_metric,
      control = control_resamples(
        save_pred = TRUE,
        event_level = "second"
      )
    ) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.glmnet", ext = "rds"))
}

# Calculate resampled metrics
rsmetrics.glmnet <-
  collect_predictions(resamples.glmnet) %>%
  group_by(id, id2) %>%
  helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second") %>%
  group_by(.metric) %>%
  summarise(.estimate = mean(.estimate), .groups = "drop_last")

# Calculate optimal thresholds resample-wise and average the results ----
thresholds.glmnet <-
  resamples.glmnet %>%
  collect_predictions(summarize = FALSE) %>%
  group_by(id, id2) %>%
  threshold_perf(
    truth = intraop_transfusion,
    estimate = .pred_yes,
    thresholds = seq(0, 1, by = 0.01)
  ) %>% 
  filter(.metric %in% c("spec", "sens", "distance")) %>%
  spread(.metric, .estimate) %>%
  mutate(distance_abs = abs(sens - spec)) %>%
  group_by(id, id2) %>%
  filter(distance_abs == min(distance_abs)) %>%
  ungroup() %>%
  summarise(
    .threshold = mean(.threshold),
    distance = mean(distance),
    sens = mean(sens),
    spec = mean(spec),
    distance_abs = mean(distance_abs)
  )

# Calculate test set metrics
testmetrics.glmnet <-
  predict(fit.glmnet, tibble.transfusion_test, type = "prob") %>%
  bind_cols(predict(fit.glmnet, tibble.transfusion_test)) %>%
  bind_cols(tibble.transfusion_test %>% select(intraop_transfusion)) %>%
  helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second")

# Create reduced test dataset
# tibble.transfusion_test_reduced <-
#   recipe.glmnet %>%
#   prep(training = tibble.transfusion_test) %>%
#   juice()

# Create explainer ----
explainer.glmnet <-
  explain_tidymodels(
    fit.glmnet,
    label = "Elastic Net Logistic Regression",
    data = tibble.transfusion_test %>% select(-intraop_transfusion),
    y = helper.y_test
  )


# Create model performance object ----
mp.glmnet <-
  model_performance(explainer.glmnet, cutoff = pluck(thresholds.glmnet, ".threshold"))

# Create variable importance object ----
vi.glmnet <-
  feature_importance(
    explainer.glmnet,
    loss_function = loss_one_minus_auc,
    label = "Elastic Net Logistic Regression",
    type = "difference",
    N = NULL # use whole dataset
  )

```

#### Random Forest

```{r ml_randomforest, eval=FALSE, include=FALSE}

# Detect cores for parallelization ----
helper.cores <- parallel::detectCores()

# Create recipe for data preparation ----
recipe.rf <-
  recipe(
    formula = intraop_transfusion ~ .,
    data = tibble.transfusion_train
  ) %>%
  # step_relevel(all_outcomes(), ref_level = "no") %>% # , skip = TRUE
  step_rm(-any_of(helper.variable_names), -all_outcomes()) %>%
  step_corr(all_numeric()) %>%
  # step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_predictors()) %>%
  # step_nzv(all_predictors()) %>%
  step_lincomb(all_numeric()) # %>%
  # step_normalize(all_numeric()) # %>%

model.rf <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_engine("ranger", num.threads = helper.cores) %>% 
  set_mode("classification")

workflow.rf <-
  workflow() %>%
  add_recipe(recipe.rf) %>%
  add_model(model.rf)

if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "tune.rf", ext = "rds"))) {
  tune.rf <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "tune.rf", ext = "rds"))
} else {
  tune.rf <-
    workflow.rf %>%
    tune_grid(
      resamples = helper.training_folds,
      grid = 25,
      control = control_grid(save_pred = TRUE, event_level = "second"),
      metrics = helper.multi_metric
    ) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "tune.rf", ext = "rds"))
}

besttune.rf <-
  tune.rf %>%
  select_best(metric = "roc_auc")

finalwf.rf <-
  workflow.rf %>%
  finalize_workflow(besttune.rf)

fit.rf <-
  finalwf.rf %>%
  fit(data = tibble.transfusion_train)

# Create cross-validation resamples ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "resamples.rf", ext = "rds"))) {
  resamples.rf <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.rf", ext = "rds"))
} else {
  resamples.rf <-
    finalwf.rf %>%
    fit_resamples(
      helper.training_folds,
      metrics = helper.multi_metric,
      control = control_resamples(
        save_pred = TRUE,
        event_level = "second"
      )
    ) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.rf", ext = "rds"))
}

# Calculate resampled metrics
rsmetrics.rf <-
  collect_predictions(resamples.rf) %>%
  group_by(id, id2) %>%
  helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second") %>%
  group_by(.metric) %>%
  summarise(.estimate = mean(.estimate), .groups = "drop_last")

# Calculate optimal thresholds resample-wise and average the results ----
thresholds.rf <-
  resamples.rf %>%
  collect_predictions(summarize = FALSE) %>%
  group_by(id, id2) %>%
  threshold_perf(
    truth = intraop_transfusion,
    estimate = .pred_yes,
    thresholds = seq(0, 1, by = 0.01)
  ) %>% 
  filter(.metric %in% c("spec", "sens", "distance")) %>%
  spread(.metric, .estimate) %>%
  mutate(distance_abs = abs(sens - spec)) %>%
  group_by(id, id2) %>%
  filter(distance_abs == min(distance_abs)) %>%
  ungroup() %>%
  summarise(
    .threshold = mean(.threshold),
    distance = mean(distance),
    sens = mean(sens),
    spec = mean(spec),
    distance_abs = mean(distance_abs)
  )

# Calculate test set metrics
testmetrics.rf <-
  predict(fit.rf, tibble.transfusion_test, type = "prob") %>%
  bind_cols(predict(fit.rf, tibble.transfusion_test)) %>%
  bind_cols(tibble.transfusion_test %>% select(intraop_transfusion)) %>%
  helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second")

# Create reduced test dataset
# tibble.transfusion_test_reduced <-
#   recipe.glmnet %>%
#   prep(training = tibble.transfusion_test) %>%
#   juice()

# Create explainer ----
explainer.rf <-
  explain_tidymodels(
    fit.rf,
    label = "Random Forest",
    data = tibble.transfusion_test %>% select(-intraop_transfusion),
    y = helper.y_test
  )


# Create model performance object ----
mp.rf <-
  model_performance(explainer.rf, cutoff = pluck(thresholds.rf, ".threshold"))

# Create variable importance object ----
vi.rf <-
  feature_importance(
    explainer.rf,
    loss_function = loss_one_minus_auc,
    label = "Random Forest",
    type = "difference",
    N = NULL # use whole dataset
  )

```

#### Support Vector Machine (RBF)

```{r ml_svmradial, eval=FALSE, include=FALSE}

# Create recipe for data preparation ----
recipe.svm <-
  recipe(
    formula = intraop_transfusion ~ .,
    data = tibble.transfusion_train
  ) %>%
  # step_relevel(all_outcomes(), ref_level = "no") %>% # , skip = TRUE
  step_rm(-any_of(helper.variable_names), -all_outcomes()) %>%
  step_corr(all_numeric()) %>%
  # step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_predictors()) %>%
  # step_nzv(all_predictors()) %>%
  step_lincomb(all_numeric()) # %>%
  # step_normalize(all_numeric()) # %>%

model.svm <- 
  svm_rbf(cost = tune(), rbf_sigma = tune()) %>% 
  set_engine("kernlab") %>% 
  set_mode("classification")

workflow.svm <-
  workflow() %>%
  add_recipe(recipe.svm) %>%
  add_model(model.svm)

if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "tune.svm", ext = "rds"))) {
  tune.svm <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "tune.svm", ext = "rds"))
} else {
  tune.svm <-
    workflow.svm %>%
    tune_grid(
      resamples = helper.training_folds,
      grid = grid_regular(cost(), rbf_sigma(), levels = 10),
      control = control_grid(save_pred = TRUE, event_level = "second"),
      metrics = helper.multi_metric) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "tune.svm", ext = "rds"))
}

besttune.svm <-
  tune.svm %>%
  select_best(metric = "roc_auc")

finalwf.svm <-
  workflow.svm %>%
  finalize_workflow(besttune.svm)

fit.svm <-
  finalwf.svm %>%
  fit(data = tibble.transfusion_train)

# Create cross-validation resamples ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "resamples.svm", ext = "rds"))) {
  resamples.svm <-
    read_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.svm", ext = "rds"))
} else {
  resamples.svm <-
    finalwf.svm %>%
    fit_resamples(
      helper.training_folds,
      metrics = helper.multi_metric,
      control = control_resamples(
        save_pred = TRUE,
        event_level = "second"
      )
    ) %>%
    write_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "resamples.svm", ext = "rds"))
}

# Calculate resampled metrics
rsmetrics.svm <-
  collect_predictions(resamples.svm) %>%
  group_by(id, id2) %>%
  helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second") %>%
  group_by(.metric) %>%
  summarise(.estimate = mean(.estimate), .groups = "drop_last")

# Calculate optimal thresholds resample-wise and average the results ----
thresholds.svm <-
  resamples.svm %>%
  collect_predictions(summarize = FALSE) %>%
  group_by(id, id2) %>%
  threshold_perf(
    truth = intraop_transfusion,
    estimate = .pred_yes,
    thresholds = seq(0, 1, by = 0.01)
  ) %>% 
  filter(.metric %in% c("spec", "sens", "distance")) %>%
  spread(.metric, .estimate) %>%
  mutate(distance_abs = abs(sens - spec)) %>%
  group_by(id, id2) %>%
  filter(distance_abs == min(distance_abs)) %>%
  ungroup() %>%
  summarise(
    .threshold = mean(.threshold),
    distance = mean(distance),
    sens = mean(sens),
    spec = mean(spec),
    distance_abs = mean(distance_abs)
  )

# Calculate test set metrics
testmetrics.svm <-
  predict(fit.svm, tibble.transfusion_test, type = "prob") %>%
  bind_cols(predict(fit.svm, tibble.transfusion_test)) %>%
  bind_cols(tibble.transfusion_test %>% select(intraop_transfusion)) %>%
  helper.multi_metric(truth = intraop_transfusion, .pred_yes, estimate = .pred_class, event_level = "second")

# Create explainer ----
explainer.svm <-
  explain_tidymodels(
    fit.svm,
    label = "Support Vector Machine (RBF)",
    data = tibble.transfusion_test %>% select(-intraop_transfusion),
    y = helper.y_test
  )


# Create model performance object ----
mp.svm <-
  model_performance(explainer.svm, cutoff = pluck(thresholds.rf, ".threshold"))

# Create variable importance object ----
vi.svm <-
  feature_importance(
    explainer.svm,
    loss_function = loss_one_minus_auc,
    label = "Support Vector Machine (RBF)",
    type = "difference",
    N = NULL # use whole dataset
  )

```

<!-- #### eXtreme Gradient Boosting Machine -->

```{r ml_xgb, eval=FALSE, include=FALSE}
# 
# # Create trainControl helper ----
# helper.trainControl_xgb <-
#   trainControl(
#     method = "repeatedcv",
#     number = 10,
#     repeats = 10,
#     allowParallel = TRUE,
#     returnData = FALSE,
#     classProbs = TRUE,
#     index = helper.training_folds,
#     savePredictions = "all",
#     summaryFunction = function(...) customTwoClassSummary(..., positive = "yes", negative="no")
#   )
# 
# # Load model, otherwise create it ----
# if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_xgb", ext = "rds"))) {
#   model.classif_xgb <-
#     read_rds(file = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_xgb", ext = "rds"))
# } else {
#   model.classif_xgb <-
#     train(
#       helper.model_formula,
#       data = tibble.transfusion_train,
#       method="xgbTree",
#       preProcess = c("center", "scale"),
#       tuneLength = 10,
#       trControl = helper.trainControl_xgb,
#       metric = "ROC"
#     ) %>%
#     write_rds(
#       file = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_xgb", ext = "rds")
#     )
# }
# 
# # Create explainer ----
# explainer.classif_xgb <-
#   explain(
#     model.classif_xgb,
#     label = "eXtreme Gradient Boosting Machine",
#     data = tibble.transfusion_test %>% select(-intraop_transfusion),
#     y = helper.y_test,
#     predict_function = p_fun
#   )
# 
# # Create model performance object ----
# mp.classif_xgb <-
#   model_performance(explainer.classif_xgb)
# 
# # Create variable importance object ----
# vi.classif_xgb <-
#   variable_importance(
#     explainer.classif_xgb,
#     loss_function = loss_one_minus_auc,
#     label = "eXtreme Gradient Boosting Machine",
#     type = "difference"
#   )
# 
# Create resamples for cut-off
# suppressWarnings(
#   resample.classif_xgb <-
#     thresholder(
#       model.classif_xgb,
#       threshold = seq(0, 1, 0.01),
#       final = TRUE
#     )
# )

```

#### Model performance

```{r model_performance, eval=FALSE, include=FALSE}

# Assemble performances
helper.performance_list <- list(
  "Stepwise Logistic Regression" = testmetrics.glm,
  "Elastic Net Logistic Regression" = testmetrics.glmnet,
  "Random Forest" = testmetrics.rf,
  "Support Vector Machine" = testmetrics.svm #,
  # "eXtreme Gradient Boosting Machine" = mp.classif_xgb
)

# Create performance table
helper.performance_list %>%
bind_rows(.id = "Model") %>%
pivot_wider(id_cols = Model, names_from = .metric, values_from = .estimate) %>%
arrange(desc(roc_auc)) %>%
mutate(across(where(is.numeric), round, digits = 3)) %>%
select(Model, Accuracy = accuracy, AUC = roc_auc, Brier = my_brier) %>%
knitr::kable()

```

#### Feature importance

```{r ml_importance, eval=FALSE, include=FALSE}

plot(
  vi.glm,
  vi.glmnet,
  vi.rf,
  vi.svm, #,
  # vi.classif_xgb,
  max_vars = 10
)

```

#### Optimal cutpoint

```{r ml_cutpoint_table, eval=FALSE, include=FALSE}

helper.cutpoint_table <-
  list(
    "Stepwise Logistic Regression" = thresholds.glm,
    "Elastic Net Logistic Regression" = thresholds.glmnet,
    "Random Forest" = thresholds.rf,
    "Support Vector Machine" = thresholds.svm #,
    # "eXtreme Gradient Boosting Machine" = resample.classif_xgb
  ) %>%
  bind_rows(.id = "model") %>%
  arrange(distance_abs) %>%
  select(Model = model, Threshold = .threshold, Sensitivity = sens, Specificity = spec, Distance = distance_abs)

helper.cutpoint_table %>%
  knitr::kable(caption = "Optimal probability threshold by absolute distance to optimal model (sensitivity and specificity = 1")

```

<!-- Cutpoint by absolute distance to optimal model (sensitivity and specificity = 1) -->

```{r ml_cutpoint_distance, eval=FALSE, include=FALSE}

# list(
#   "Stepwise Logistic Regression" = thresholds.glm,
#   "Elastic Net Logistic Regression" = thresholds.glmnet,
#   "Random Forest" = thresholds.rf,
#   "Support Vector Machine" = thresholds.svm #,
#   # "eXtreme Gradient Boosting Machine" = resample.classif_xgb
# ) %>%
#   bind_rows(.id = "model") %>%
#   ggplot(aes(x = .threshold, y = distance_abs, colour = model)) +
#   geom_line() +
#   scale_colour_viridis_d() +
#   labs(title = "Absolute distance to optimal model", subtitle = "(1 - Specificity) + (1 - Sensitivity)", x = "Probability threshold", y = "Absolute distance", colour = "Model")
  
```

<!-- Cutpoint by sensitivity and specificity -->

```{r ml_cutpoint, eval=FALSE, include=FALSE}

# list(
#   "Stepwise Logistic Regression" = resample.classif_glmstep,
#   "Random Forest" = resample.classif_rf,
#   "Elastic Net Logistic Regression" = resample.classif_glmnet,
#   "Support Vector Machine" = resample.classif_svmradial #,
#   # "eXtreme Gradient Boosting Machine" = resample.classif_xgb
# ) %>%
#   bind_rows(.id = "model") %>%
#   pivot_longer(Sensitivity:sigma, names_to = "Parameter", values_to = "Value") %>%
#   filter(Parameter == "Sensitivity" | Parameter == "Specificity") %>%
#   ggplot(aes(x = prob_threshold, y = Value, colour = Parameter)) +
#   facet_wrap(vars(model)) +
#   geom_line() +
#   scale_colour_viridis_d(direction = -1) +
#   labs(title = "Sensitivity vs. Specificity", x = "Probability threshold", y = "Sensitivity/Specificity", colour = "Parameter")
#   
```


```{r ml_predictions, eval=FALSE, include=FALSE}

# list(
#   "Stepwise Logistic Regression" = model.classif_glmstep,
#   "Random Forest" = model.classif_rf,
#   "Elastic Net Logistic Regression" = model.classif_glmnet,
#   "Support Vector Machine" = model.classif_svmradial #,
#   # "eXtreme Gradient Boosting Machine" = model.classif_xgb
# ) %>%
#   predict(newdata = tibble.transfusion_test, type = "prob") %>%
#   map2(
#     list(
#       rep(0.29),
#       rep(0.34),
#       rep(0.33),
#       rep(0.34) #,
#       # rep()
#     ),
#     bind_cols
#   ) %>%
#   map(rename, threshold = `...3`) %>%
#   map(function(prediction_p) {p_class <- ifelse(prediction_p$yes > prediction_p$threshold, "yes", "no")}) %>%
#   map(factor, levels = c("yes", "no")) %>%
#   map(caret::confusionMatrix, reference = tibble.transfusion_test$intraop_transfusion, mode = "everything") %>%
#   imap(function(result, index) {print(result)})

tibble.single_patient.notnumeric <-
  tibble(
    oak = FALSE,
    tcaggr = FALSE,
    cci_5plus = factor("0"),
    gender = factor("male"),
    p_tumor = factor("0"),
    p_node_pos = FALSE,
    previous_op = FALSE,
    norepinephrine = FALSE,
    neoadj_chemo = FALSE
  )

tibble.single_patient.mean <-
  bind_rows(tibble.transfusion_train, tibble.transfusion_test) %>%
  summarise(across(where(is.numeric), mean)) %>%
  bind_cols(tibble.single_patient.notnumeric)

```

# Methods

Baseline, intra-operative and postoperative variables were compared between patients who received intraoperative blood product (packed red blood cells, fresh frozen plasma or platelet concentrate) transfusions and those who did not. Data were expressed as median with interquartile range for continuous variables and frequencies for categorical ones. We performed exploratory landmark analyses for categorical data using the $\chi^2$ test, and for continuous data the Kruskal-Wallis test.

For model validation we held out 20% of the data. We repeatedly split the remaining 80% into ten folds for cross-validation for ten repetitions overall. Multiple logistic regression analyses using a stepwise selection procedure (minimizing Akaike's Information Criterion AIC) as well as using repeated 10-fold cross-validation for averaging ROC-AUC were applied to identify independent risk factors for intraoperative blood product transfusion and reported as Wald $\chi^2$ *P* value and adjusted odds ratio (OR) with 95% confidence intervals (CI). Factors that were selected a priori based on their potential association with intraoperative blood product transfusion were blood loss ratio, use of oral anticoagulants or platelet inhibitors, preoperative Hb values, BMI, age, sex, Charlson comorbidity index (CCI), tumor stage, positive nodal stage, duration of surgery, presence of previous surgery, use of noradrenaline, intra-operative volumes of crystalloids administered and presence of neoadjuvant chemotherapy.