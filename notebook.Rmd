---
title: "R Notebook for the cystectomy study"
author: "Pascal Jerney"
date: "30th August 2020"
output:
  bookdown::gitbook:
    config:
      toc:
        collapse: subsection
        scroll_highlight: yes
        before: null
        after: null
      toolbar:
        position: fixed
      edit : null
      download:
        - ["notebook.pdf", "PDF"]
      search: yes
      fontsettings:
        theme: white
        family: sans
        size: 2
      sharing:
        facebook: yes
        github: no
        twitter: yes
        linkedin: no
        weibo: no
        instapaper: no
        vk: no
        all: ['facebook', 'twitter', 'linkedin', 'weibo', 'instapaper']
      info: yes
  html_notebook: default
  bookdown::pdf_document2:
    toc: false
    keep_tex: true
    latex_engine: xelatex
---

```{r setup, echo=FALSE}
# Load packages ----
if (!require("pacman")) {
  install.packages("pacman")
}
pacman::p_load(
  "tidyverse",
  "rprojroot",
  "fs",
  "tableone",
  "modelr",
  "glue",
  "gridExtra",
  "pander",
  "htmltools",
  "MASS",
  "car",
  "recipes",
  "ROCR",
  "DALEX",
  "caret"
)
pacman::p_unload("MASS")

# Set working directory ----
setwd(rprojroot::find_rstudio_root_file())
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png",
  dpi = 300,
  fig.asp = 0.8,
  fig.width = 10,
  out.width = "100%",
  fig.align = "center"
)

# Functions ----
opt.cut <- function(perf, pred){
    cut.ind = mapply(FUN=function(x, y, p){
        d = (x - 0)^2 + (y-1)^2
        ind = which(d == min(d))
        c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
            cutoff = p[[ind]])
    }, perf@x.values, perf@y.values, pred@cutoffs)
}

`%!in%` <- Negate(`%in%`)

p_fun <-
  function(object, newdata) {
    predict(object, newdata = newdata, type = "prob")[,2]
  }

fourStats <- function (data, lev = levels(data$obs), model = NULL) {
  ## This code will get use the area under the ROC curve and the
  ## sensitivity and specificity values using the current candidate
  ## value of the probability threshold.
  out <- c(twoClassSummary(data, lev = levels(data$obs), model = NULL))
 
  ## The best possible model has sensitivity of 1 and specifity of 1. 
  ## How far are we from that value?
  coords <- matrix(c(1, 1, out["Spec"], out["Sens"]), 
                   ncol = 2, 
                   byrow = TRUE)
  colnames(coords) <- c("Spec", "Sens")
  rownames(coords) <- c("Best", "Current")
  c(out, Dist = dist(coords)[1])
}

# Load data from 0_get_and_tidy_data ----
tibble.oak_bleeding_model <-
  read_rds(path = path_wd(
    'empirical',
    '2_pipeline',
    '1_get_and_tidy_data',
    'out',
    'oak_bleeding_model',
    ext = 'rds'
  ))

# Create helper for Table 1 ----
helper.tableone <- c(
  "blood_loss_ml",
  "blood_loss_ratio",
  "oak",
  "tcaggr",
  "preop_hb",
  "preop_tc",
  "bmi",
  "age",
  "cci_5plus",
  "gender",
  "p_tumor",
  "p_node_pos",
  # "op_year",
  "op_duration_min",
  "previous_op",
  "norepinephrine",
  "crystalloids_mlkgh",
  "neoadj_chemo"
)

# Create Table 1 ----
table.oak_bleeding_model <-
  tibble.oak_bleeding_model %>%
  CreateTableOne(
    vars = helper.tableone,
    strata = c("intraop_transfusion"),
    data = .,
    test = TRUE
  ) %>%
  print(., nonnormal = c(
    "blood_loss_ml",
    "blood_loss_ratio",
    "preop_hb",
    "preop_tc",
    "bmi",
    "age",
    "op_duration_min",
    "crystalloids_mlkgh"
  ), printToggle = FALSE, noSpaces = TRUE)

# Load helper for variable selection ----
helper.variable_selection <- c(
  "blood_loss_ratio",
  "oak",
  "tcaggr",
  "preop_hb",
  "preop_tc",
  "bmi",
  "age",
  "cci_5plus",
  "gender",
  "p_tumor",
  "p_node_pos",
  "op_duration_min",
  "previous_op",
  "norepinephrine",
  "crystalloids_mlkgh",
  "neoadj_chemo"
)

# Create variable name helper for model formula generation ----
helper.variables_names <- c(
  "poly(blood_loss_ratio, 2)",
  "oak",
  "tcaggr",
  "poly(preop_hb, 2)",
  "preop_tc",
  "bmi",
  "poly(age, 2)",
  "cci_5plus",
  "gender",
  "p_tumor",
  "p_node_pos",
  "op_duration_min",
  "previous_op",
  "norepinephrine",
  "crystalloids_mlkgh",
  "neoadj_chemo"
)

# Create formula helper for models ----
helper.model_formula <-
  as.formula(
    glue(
      "as.factor(intraop_transfusion) ~ ",
      paste(c(helper.variables_names[!helper.variables_names %in% c("intraop_transfusion")]), collapse = " + ")
    )
  )

# Create recipe for data preparation ----
recipe.bleeding_model <-
  recipe(
    formula = as.formula(glue("intraop_transfusion ~ ", paste(helper.variable_selection, collapse = "+"))),
    data = tibble.oak_bleeding_model
  ) %>%
  step_mutate_at(all_outcomes(), fn = as.numeric) %>%
  step_num2factor(all_outcomes(), transform = function(x) x + 1, levels = c("no", "yes")) %>%
  # step_relevel(all_outcomes(), ref_level = "no") %>%
  step_corr(all_numeric()) %>%
  step_zv(all_predictors()) %>%
  # step_nzv(all_predictors()) %>%
  step_lincomb(all_numeric()) %>%
  prep()

# Bake the dataset ----
tibble.oak_bleeding_model_clean <-
  recipe.bleeding_model %>%
  bake(tibble.oak_bleeding_model)

# Create helper for partitioning ----
helper.training_test <-
  createDataPartition(
    tibble.oak_bleeding_model_clean$intraop_transfusion,
    p = 0.8,
    list = FALSE
  )

# Partition into training and test dataset ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_train", ext = "rds"))) {
  tibble.oak_bleeding_model_train <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_train", ext = "rds"))
} else {
  tibble.oak_bleeding_model_train <-
    tibble.oak_bleeding_model_clean %>%
    rownames_to_column() %>%
    filter(rowname %in% helper.training_test) %>%
    select(-rowname) %>%
    write_rds(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_train", ext = "rds"))
}

if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_test", ext = "rds"))) {
  tibble.oak_bleeding_model_test <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_test", ext = "rds"))
} else {
  tibble.oak_bleeding_model_test <-
    tibble.oak_bleeding_model_clean %>%
    rownames_to_column() %>%
    filter(rowname %!in% helper.training_test) %>%
    select(-rowname) %>%
    write_rds(path = path_wd("paper", "notebook", "notebook_files", "data", "tibble.oak_bleeding_model_test", ext = "rds"))
}

# Create separate vector for the outcome variable ----
helper.y_test <-
  tibble.oak_bleeding_model_test %>%
  # modify_at(vars(intraop_transfusion), as.character) %>%
  modify_at(vars(intraop_transfusion), as.numeric) %>%
  mutate(intraop_transfusion = intraop_transfusion - 1) %>%
  pull(intraop_transfusion)

```

# Index

Welcome to the notebook!

## Table 1

```{r table_one,echo=FALSE}

# Print Table 1 ----
table.oak_bleeding_model %>%
  knitr::kable()

```

# Prerequisites

## Formulas

  - Indexed blood volume^[Lemmens, H. J. M., Bernstein, D. P., & Brodsky, J. B. (2006). Estimating blood volume in obese and morbidly obese patients. Obesity Surgery, 16(6), 773â€“776. https://doi.org/10.1381/096089206777346673]: $BV_i = \frac{70}{\sqrt{\frac{BMI}{22}}}$^[$BV_i$ = Indexed blood volume, $BMI$ = Body mass index]
  - Estimated blood volume: $BV_e = BV_i \cdot Weight$^[$BV_e$ = Estimated blood volume]
  - Blood loss ratio: $BL_r = \frac{BV_e}{BL_a}$^[$BL_r$ = Blood loss ratio, $BL_a$ = Absolute blood loss]
  - Standardization method for age and bmi^[Iglewicz, B., & Hoaglin, D. C. (1993). How to detect and handle outliers. Milwaukee, Wis: ASQC Quality Press.]: $M_i = \frac{0.6745(x_i - \tilde(x))}{2 \cdot MAD}$^[$M_i$ = Modified Z-score, $\tilde(x)$ = Median of $x$, $MAD$ = Median absolute deviation]

# Results

## Data plots

```{r data_plots,echo=FALSE}

# Print QQ plots ----
qqplot_bloodlossratio <-
  tibble.oak_bleeding_model %>%
  drop_na(blood_loss_ratio) %>%
  ggplot(aes(sample = blood_loss_ratio)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "Q-Q-Plot for blood loss ratio", subtitle = "Normal scale", x = "Theoretical quantiles", y = "Sample quantiles") +
  theme_light()

qqplot_logbloodlossratio <-
  tibble.oak_bleeding_model %>%
  drop_na(blood_loss_ratio) %>%
  ggplot(aes(sample = log(blood_loss_ratio))) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "Q-Q-Plot for blood loss ratio", subtitle = "Natural logarithm scale", x = "Theoretical quantiles", y = "Sample quantiles") +
  theme_light()

grid.arrange(qqplot_bloodlossratio, qqplot_logbloodlossratio, ncol = 2)

# Print histogram of blood_loss_ratio ----
tibble.oak_bleeding_model %>%
drop_na(blood_loss_ratio) %>%
ggplot(aes(x = blood_loss_ratio)) +
geom_histogram(binwidth = 0.05) +
labs(title = "Histogram of blood loss ratio", x = "Blood loss ratio", y = "Count") +
theme_light()

# Print bar chart of intraop_transfusion ----
tibble.oak_bleeding_model %>%
drop_na(intraop_transfusion) %>%
ggplot(aes(x = intraop_transfusion)) +
geom_bar() +
labs(title = "Bar chart of intraoperative transfusion", x = "Intraoperative transfusion", y = "Count") +
theme_light()
```

## Model outputs

### Models with intraoperative transfusion as response

#### Stepwise Logistic Regression

```{r glm_stepwise,echo=FALSE}

# Create trainControl helper ----
helper.trainControl_glmstep <-
  trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    returnData = FALSE,
    classProbs = TRUE,
    savePredictions = "all",
    summaryFunction = twoClassSummary
  )

# Load model, otherwise create it ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_glmstep", ext = "rds"))) {
  model.classif_glmstep <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_glmstep", ext = "rds"))
} else {
  model.classif_glmstep <-
    train(
      helper.model_formula,
      data = tibble.oak_bleeding_model_train,
      method = "glmStepAIC",
      preProcess = c("center", "scale"),
      family = "binomial",
      trControl = helper.trainControl_glmstep,
      metric = "ROC",
      trace = FALSE,
      direction = "both"
    ) %>%
    write_rds(
      path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_glmstep", ext = "rds")
    )
}

# Create explainer ----
explainer.classif_glmstep <-
  explain(
    model.classif_glmstep,
    label = "Stepwise Logistic Regression",
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = p_fun
  )

# Create model performance object ----
mp.classif_glmstep <-
  model_performance(explainer.classif_glmstep)

# Create variable importance object ----
vi.classif_glmstep <-
  variable_importance(
    explainer.classif_glmstep,
    loss_function = loss_one_minus_auc,
    label = "Stepwise Logistic Regression",
    type = "difference"
  )

# Create resamples for cut-off
resample.classif_glmstep <-
  thresholder(
    model.classif_glmstep,
    threshold = seq(0, 1, 0.01),
    final = TRUE
  )

# model.glm.intraoptransfusion_full <-
#   glm(
#     formula = helper.glm_formula_full,
#     data = tibble.oak_bleeding_model_train,
#     family = binomial()
#   ) %>%
#   MASS::stepAIC(scope = list(upper = helper.glm_formula_full, lower = ~ 1), trace = FALSE) %>%
#   write_rds(
#     path = path_wd("paper", "notebook", "notebook_files", "models", "model.glm_intraoptransfusion_full", ext = "rds")
#   )
# 
# model.glm.intraoptransfusion_full_scaled <-
#   update(
#     model.glm.intraoptransfusion_full,
#     formula. = ~ . - blood_loss_ratio + I(blood_loss_ratio * 100) - preop_hb + I(preop_hb * 10)
#   ) %>%
#   write_rds(
#     path = path_wd("paper", "notebook", "notebook_files", "models", "model.glm_intraoptransfusion_full_scaled", ext = "rds")
#   )
# 
# summary(model.glm.intraoptransfusion_full)
# 
# summary(model.glm.intraoptransfusion_full_scaled)

```

#### Random Forest

```{r ml_randomforest,echo=FALSE}

# Create trainControl helper ----
helper.trainControl_rf <-
  trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    returnData = FALSE,
    classProbs = TRUE,
    savePredictions = "all",
    summaryFunction = twoClassSummary
  )

# Load model, otherwise create it ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_rf", ext = "rds"))) {
  model.classif_rf <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_rf", ext = "rds"))
} else {
  model.classif_rf <-
    train(
      helper.model_formula,
      data = tibble.oak_bleeding_model_train,
      method = "rf",
      preProcess = c("center", "scale"),
      ntree = 501,
      tuneLength = 25,
      trControl = helper.trainControl_rf,
      metric = "ROC"
    ) %>%
    write_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_rf", ext = "rds"))
}

# Create explainer ----
explainer.classif_rf <-
  explain(
    model.classif_rf,
    label = "Random Forest",
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = p_fun
  )

# Create model performance object ----
mp.classif_rf <-
  model_performance(explainer.classif_rf)

# Create variable importance object ----
vi.classif_rf <-
  variable_importance(
    explainer.classif_rf,
    loss_function = loss_one_minus_auc,
    label = "Random Forest",
    type = "difference"
  )

# Create resamples for cut-off
resample.classif_rf <-
  thresholder(
    model.classif_rf,
    threshold = seq(0, 1, 0.01),
    final = TRUE
  )

```

#### Elastic Net Logistic Regression

```{r ml_elasticnet,echo=FALSE}

# Create trainControl helper ----
helper.trainControl_glmnet <-
  trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    returnData = FALSE,
    classProbs = TRUE,
    savePredictions = "all",
    summaryFunction = twoClassSummary
  )

# Load model, otherwise create it ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_glmnet", ext = "rds"))) {
  model.classif_glmnet <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_glmnet", ext = "rds"))
} else {
  model.classif_glmnet <-
    train(
      helper.model_formula,
      data = tibble.oak_bleeding_model_train,
      method = "glmnet",
      preProcess = c("center", "scale"),
      family = "binomial",
      tuneLength = 25,
      trControl = helper.trainControl_glmnet,
      metric = "ROC"
    ) %>%
    write_rds(
      path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_glmnet", ext = "rds")
    )
}

# Create explainer ----
explainer.classif_glmnet <-
  explain(
    model.classif_glmnet,
    label = "Elastic Net Logistic Regression",
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = p_fun
  )

# Create model performance object ----
mp.classif_glmnet <-
  model_performance(explainer.classif_glmnet)

# Create variable importance object ----
vi.classif_glmnet <-
  variable_importance(
    explainer.classif_glmnet,
    loss_function = loss_one_minus_auc,
    label = "Elastic Net Logistic Regression",
    type = "difference"
  )

# Create resamples for cut-off
resample.classif_glmnet <-
  thresholder(
    model.classif_glmnet,
    threshold = seq(0, 1, 0.01),
    final = TRUE
  )

```

#### Support Vector Machine (RBF)

```{r ml_svmradial,echo=FALSE}

# Create trainControl helper ----
helper.trainControl_svmradial <-
  trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    returnData = FALSE,
    classProbs = TRUE,
    savePredictions = "all",
    summaryFunction = twoClassSummary
  )

# Load model, otherwise create it ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_svmradial", ext = "rds"))) {
  model.classif_svmradial <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_svmradial", ext = "rds"))
} else {
  model.classif_svmradial <-
    train(
      helper.model_formula,
      data = tibble.oak_bleeding_model_train,
      method="svmRadial",
      preProcess = c("center", "scale"),
      prob.model = TRUE,
      tuneLength = 10,
      trControl = helper.trainControl_svmradial,
      metric = "ROC"
    ) %>%
    write_rds(
      path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_svmradial", ext = "rds")
    )
}

# Create explainer ----
explainer.classif_svmradial <-
  explain(
    model.classif_svmradial,
    label = "Support Vector Machine",
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = p_fun
  )

# Create model performance object ----
mp.classif_svmradial <-
  model_performance(explainer.classif_svmradial)

# Create variable importance object ----
vi.classif_svmradial <-
  variable_importance(
    explainer.classif_svmradial,
    loss_function = loss_one_minus_auc,
    label = "Support Vector Machine",
    type = "difference"
  )

# Create resamples for cut-off
resample.classif_svmradial <-
  thresholder(
    model.classif_svmradial,
    threshold = seq(0, 1, 0.01),
    final = TRUE
  )

```

#### eXtreme Gradient Boosting Machine

```{r ml_xgb,echo=FALSE}

# Create trainControl helper ----
helper.trainControl_xgb <-
  trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10,
    allowParallel = TRUE,
    returnData = FALSE,
    classProbs = TRUE,
    savePredictions = "all",
    summaryFunction = twoClassSummary
  )

# Load model, otherwise create it ----
if(file_exists(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_xgb", ext = "rds"))) {
  model.classif_xgb <-
    read_rds(path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_xgb", ext = "rds"))
} else {
  model.classif_xgb <-
    train(
      helper.model_formula,
      data = tibble.oak_bleeding_model_train,
      method="xgbTree",
      preProcess = c("center", "scale"),
      tuneLength = 10,
      trControl = helper.trainControl_xgb,
      metric = "ROC"
    ) %>%
    write_rds(
      path = path_wd("paper", "notebook", "notebook_files", "models", "model.classif_xgb", ext = "rds")
    )
}

# Create explainer ----
explainer.classif_xgb <-
  explain(
    model.classif_xgb,
    label = "eXtreme Gradient Boosting Machine",
    data = tibble.oak_bleeding_model_test %>% select(-intraop_transfusion),
    y = helper.y_test,
    predict_function = p_fun
  )

# Create model performance object ----
mp.classif_xgb <-
  model_performance(explainer.classif_xgb)

# Create variable importance object ----
vi.classif_xgb <-
  variable_importance(
    explainer.classif_xgb,
    loss_function = loss_one_minus_auc,
    label = "eXtreme Gradient Boosting Machine",
    type = "difference"
  )

# Create resamples for cut-off
resample.classif_xgb <-
  thresholder(
    model.classif_xgb,
    threshold = seq(0, 1, 0.01),
    final = TRUE
  )

```

#### Model performance

```{r model_performance,echo=FALSE}

list(
  mp.classif_glmstep,
  mp.classif_rf,
  mp.classif_glmnet,
  mp.classif_svmradial,
  mp.classif_xgb
) %>%
map_dfr(pluck, "measures") %>%
add_column(
  tibble(
    Model = c(
      "Stepwise Logistic Regression",
      "Random Forest",
      "Elastic Net Logistic Regression",
      "Support Vector Machine",
      "eXtreme Gradient Boosting Machine"
    )
  ),
  .before = 1
) %>%
arrange(desc(auc)) %>%
modify_at(vars(recall, precision, f1, accuracy, auc), round, 2) %>%
select(Model, Recall = recall, Precision = precision, F1 = f1, Accuracy = accuracy, AUC = auc) %>%
knitr::kable()

```

#### Feature importance

```{r ml_importance,echo=FALSE}

plot(
  vi.classif_glmstep,
  vi.classif_rf,
  vi.classif_glmnet,
  vi.classif_svmradial,
  vi.classif_xgb
)

```

#### Optimal cutpoint

Cutpoint table

```{r ml_cutpoint_table,echo=FALSE}

list(
  "Stepwise Logistic Regression" = resample.classif_glmstep,
  "Random Forest" = resample.classif_rf,
  "Elastic Net Logistic Regression" = resample.classif_glmnet,
  "Support Vector Machine" = resample.classif_svmradial,
  "eXtreme Gradient Boosting Machine" = resample.classif_xgb
) %>%
  bind_rows(.id = "model") %>%
  group_by(model) %>%
  filter(Dist == min(Dist)) %>%
  select(Model = model, Threshold = prob_threshold, Sensitivity, Specificity, `Balanced Accuracy`, J, Dist)
  
```

Cutpoint by distance to optimal model (sensitivity and specificity = 1)

```{r ml_cutpoint_distance,echo=FALSE}

list(
  "Stepwise Logistic Regression" = resample.classif_glmstep,
  "Random Forest" = resample.classif_rf,
  "Elastic Net Logistic Regression" = resample.classif_glmnet,
  "Support Vector Machine" = resample.classif_svmradial,
  "eXtreme Gradient Boosting Machine" = resample.classif_xgb
) %>%
  bind_rows(.id = "model") %>%
  ggplot(aes(x = prob_threshold, y = Dist, colour = model)) +
  geom_line() +
  scale_colour_viridis_d()
  
```

Cutpoint by sensitivity and specificity

```{r ml_cutpoint,echo=FALSE}

list(
  "Stepwise Logistic Regression" = resample.classif_glmstep,
  "Random Forest" = resample.classif_rf,
  "Elastic Net Logistic Regression" = resample.classif_glmnet,
  "Support Vector Machine" = resample.classif_svmradial,
  "eXtreme Gradient Boosting Machine" = resample.classif_xgb
) %>%
  bind_rows(.id = "model") %>%
  ggplot(aes(x = prob_threshold, y = Sensitivity)) +
  facet_wrap(vars(model)) +
  geom_line() +
  geom_line(aes(y = Specificity), colour = "red")
  
```


```{r ml_predictions,echo=FALSE}
# predict(list("Stepwise Logistic Regression" = model.classif_glmstep, "Random Forest" = model.classif_rf, "Elastic Net Logistic Regression" = model.classif_glmnet, "Support Vector Machine" = model.classif_svmradial), newdata = tibble.oak_bleeding_model_test, type = "prob") %>% map(function(prediction_p) {p_class <- ifelse(prediction_p$yes > 0.71, "yes", "no")})
```