<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Results | R Notebook for the cystectomy study</title>
  <meta name="description" content="3 Results | R Notebook for the cystectomy study" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Results | R Notebook for the cystectomy study" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Results | R Notebook for the cystectomy study" />
  
  
  

<meta name="author" content="Pascal Jerney" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="prerequisites.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Index</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#table-1"><i class="fa fa-check"></i><b>1.1</b> Table 1</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>2</b> Prerequisites</a><ul>
<li class="chapter" data-level="2.1" data-path="prerequisites.html"><a href="prerequisites.html#formulas"><i class="fa fa-check"></i><b>2.1</b> Formulas</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>3</b> Results</a><ul>
<li class="chapter" data-level="3.1" data-path="results.html"><a href="results.html#data-plots"><i class="fa fa-check"></i><b>3.1</b> Data plots</a></li>
<li class="chapter" data-level="3.2" data-path="results.html"><a href="results.html#model-outputs"><i class="fa fa-check"></i><b>3.2</b> Model outputs</a><ul>
<li class="chapter" data-level="3.2.1" data-path="results.html"><a href="results.html#models-with-intraoperative-transfusion-as-response"><i class="fa fa-check"></i><b>3.2.1</b> Models with intraoperative transfusion as response</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R Notebook for the cystectomy study</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="results" class="section level1">
<h1><span class="header-section-number">3</span> Results</h1>
<div id="data-plots" class="section level2">
<h2><span class="header-section-number">3.1</span> Data plots</h2>
<p><img src="notebook_files/figure-html/data_plots-1.png" width="100%" style="display: block; margin: auto;" /><img src="notebook_files/figure-html/data_plots-2.png" width="100%" style="display: block; margin: auto;" /><img src="notebook_files/figure-html/data_plots-3.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="model-outputs" class="section level2">
<h2><span class="header-section-number">3.2</span> Model outputs</h2>
<div id="models-with-intraoperative-transfusion-as-response" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Models with intraoperative transfusion as response</h3>
<div id="stepwise-backwards-logistic-regression-without-interactions" class="section level4">
<h4><span class="header-section-number">3.2.1.1</span> Stepwise backwards logistic regression without interactions</h4>
<pre><code>#&gt; 
#&gt; Call:
#&gt; glm(formula = intraop_transfusion ~ blood_loss_ratio + oak + 
#&gt;     preop_hb + p_tumor + norepinephrine + I(age^2), family = binomial(), 
#&gt;     data = tibble.oak_bleeding_model_train)
#&gt; 
#&gt; Deviance Residuals: 
#&gt;     Min       1Q   Median       3Q      Max  
#&gt; -2.5714  -0.6094  -0.2959   0.4135   2.8660  
#&gt; 
#&gt; Coefficients:
#&gt;                      Estimate Std. Error z value Pr(&gt;|z|)    
#&gt; (Intercept)         2.938e+00  7.754e-01   3.789 0.000151 ***
#&gt; blood_loss_ratio    1.258e+01  1.001e+00  12.561  &lt; 2e-16 ***
#&gt; oakTRUE             9.673e-01  4.435e-01   2.181 0.029174 *  
#&gt; preop_hb           -6.450e-02  6.071e-03 -10.625  &lt; 2e-16 ***
#&gt; p_tumor.L           7.405e-01  2.393e-01   3.095 0.001970 ** 
#&gt; p_tumor.Q           3.668e-01  2.286e-01   1.604 0.108671    
#&gt; p_tumor.C           2.279e-01  2.289e-01   0.996 0.319417    
#&gt; p_tumor^4          -2.019e-01  2.122e-01  -0.952 0.341170    
#&gt; norepinephrineTRUE -3.257e-01  1.953e-01  -1.668 0.095408 .  
#&gt; I(age^2)            2.828e-04  6.523e-05   4.336 1.45e-05 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; (Dispersion parameter for binomial family taken to be 1)
#&gt; 
#&gt;     Null deviance: 1167.37  on 934  degrees of freedom
#&gt; Residual deviance:  726.51  on 925  degrees of freedom
#&gt; AIC: 746.51
#&gt; 
#&gt; Number of Fisher Scoring iterations: 6
#&gt; 
#&gt; Call:
#&gt; glm(formula = intraop_transfusion ~ oak + p_tumor + norepinephrine + 
#&gt;     I(age^2) + I(blood_loss_ratio * 100) + I(preop_hb * 10), 
#&gt;     family = binomial(), data = tibble.oak_bleeding_model_train)
#&gt; 
#&gt; Deviance Residuals: 
#&gt;     Min       1Q   Median       3Q      Max  
#&gt; -2.5714  -0.6094  -0.2959   0.4135   2.8660  
#&gt; 
#&gt; Coefficients:
#&gt;                             Estimate Std. Error z value Pr(&gt;|z|)    
#&gt; (Intercept)                2.938e+00  7.754e-01   3.789 0.000151 ***
#&gt; oakTRUE                    9.673e-01  4.435e-01   2.181 0.029174 *  
#&gt; p_tumor.L                  7.405e-01  2.393e-01   3.095 0.001970 ** 
#&gt; p_tumor.Q                  3.668e-01  2.286e-01   1.604 0.108671    
#&gt; p_tumor.C                  2.279e-01  2.289e-01   0.996 0.319417    
#&gt; p_tumor^4                 -2.019e-01  2.122e-01  -0.952 0.341170    
#&gt; norepinephrineTRUE        -3.257e-01  1.953e-01  -1.668 0.095408 .  
#&gt; I(age^2)                   2.828e-04  6.523e-05   4.336 1.45e-05 ***
#&gt; I(blood_loss_ratio * 100)  1.258e-01  1.001e-02  12.561  &lt; 2e-16 ***
#&gt; I(preop_hb * 10)          -6.450e-03  6.071e-04 -10.625  &lt; 2e-16 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; (Dispersion parameter for binomial family taken to be 1)
#&gt; 
#&gt;     Null deviance: 1167.37  on 934  degrees of freedom
#&gt; Residual deviance:  726.51  on 925  degrees of freedom
#&gt; AIC: 746.51
#&gt; 
#&gt; Number of Fisher Scoring iterations: 6</code></pre>
<!-- ##### ROC-AUC for the test dataset -->
</div>
<div id="stepwise-backwards-logistic-regression-with-interactions" class="section level4">
<h4><span class="header-section-number">3.2.1.2</span> Stepwise backwards logistic regression with interactions</h4>
<pre><code>#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
#&gt; 
#&gt; Call:
#&gt; glm(formula = intraop_transfusion ~ I(blood_loss_ratio * 100) + 
#&gt;     oak + tcaggr + norepinephrine + p_tumor + I(preop_hb * 10) + 
#&gt;     I(age^2) + I(blood_loss_ratio * 100):norepinephrine + tcaggr:norepinephrine + 
#&gt;     norepinephrine:p_tumor + I(preop_hb * 10):I(age^2), family = binomial(), 
#&gt;     data = tibble.oak_bleeding_model_train)
#&gt; 
#&gt; Deviance Residuals: 
#&gt;     Min       1Q   Median       3Q      Max  
#&gt; -2.4626  -0.6136  -0.2749   0.3730   3.0500  
#&gt; 
#&gt; Coefficients:
#&gt;                                                Estimate Std. Error z value
#&gt; (Intercept)                                   6.400e+00  2.350e+00   2.724
#&gt; I(blood_loss_ratio * 100)                     1.466e-01  1.525e-02   9.614
#&gt; oakTRUE                                       8.525e-01  4.448e-01   1.917
#&gt; tcaggrTRUE                                    5.218e-01  6.069e-01   0.860
#&gt; norepinephrineTRUE                            5.965e-01  5.464e-01   1.092
#&gt; p_tumor.L                                     9.261e-01  4.200e-01   2.205
#&gt; p_tumor.Q                                     8.587e-01  3.919e-01   2.191
#&gt; p_tumor.C                                    -2.213e-01  3.799e-01  -0.583
#&gt; p_tumor^4                                    -5.561e-01  3.399e-01  -1.636
#&gt; I(preop_hb * 10)                             -9.822e-03  1.950e-03  -5.038
#&gt; I(age^2)                                     -4.939e-04  4.656e-04  -1.061
#&gt; I(blood_loss_ratio * 100):norepinephrineTRUE -2.804e-02  1.884e-02  -1.488
#&gt; tcaggrTRUE:norepinephrineTRUE                -1.148e+00  7.042e-01  -1.630
#&gt; norepinephrineTRUE:p_tumor.L                 -3.128e-01  5.124e-01  -0.610
#&gt; norepinephrineTRUE:p_tumor.Q                 -8.475e-01  4.862e-01  -1.743
#&gt; norepinephrineTRUE:p_tumor.C                  7.335e-01  4.836e-01   1.517
#&gt; norepinephrineTRUE:p_tumor^4                  5.427e-01  4.412e-01   1.230
#&gt; I(preop_hb * 10):I(age^2)                     6.444e-07  3.768e-07   1.710
#&gt;                                              Pr(&gt;|z|)    
#&gt; (Intercept)                                   0.00645 ** 
#&gt; I(blood_loss_ratio * 100)                     &lt; 2e-16 ***
#&gt; oakTRUE                                       0.05529 .  
#&gt; tcaggrTRUE                                    0.38994    
#&gt; norepinephrineTRUE                            0.27498    
#&gt; p_tumor.L                                     0.02743 *  
#&gt; p_tumor.Q                                     0.02844 *  
#&gt; p_tumor.C                                     0.56022    
#&gt; p_tumor^4                                     0.10184    
#&gt; I(preop_hb * 10)                             4.71e-07 ***
#&gt; I(age^2)                                      0.28886    
#&gt; I(blood_loss_ratio * 100):norepinephrineTRUE  0.13675    
#&gt; tcaggrTRUE:norepinephrineTRUE                 0.10317    
#&gt; norepinephrineTRUE:p_tumor.L                  0.54156    
#&gt; norepinephrineTRUE:p_tumor.Q                  0.08130 .  
#&gt; norepinephrineTRUE:p_tumor.C                  0.12933    
#&gt; norepinephrineTRUE:p_tumor^4                  0.21865    
#&gt; I(preop_hb * 10):I(age^2)                     0.08725 .  
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; (Dispersion parameter for binomial family taken to be 1)
#&gt; 
#&gt;     Null deviance: 1167.37  on 934  degrees of freedom
#&gt; Residual deviance:  709.09  on 917  degrees of freedom
#&gt; AIC: 745.09
#&gt; 
#&gt; Number of Fisher Scoring iterations: 6</code></pre>
<!-- ##### ROC-AUC for the test dataset -->
</div>
<div id="machine-learning-classification" class="section level4">
<h4><span class="header-section-number">3.2.1.3</span> Machine learning classification</h4>
</div>
<div id="model-performance" class="section level4">
<h4><span class="header-section-number">3.2.1.4</span> Model performance</h4>
<pre><code>#&gt; Preparation of a new explainer is initiated
#&gt;   -&gt; model label       :  lm  ( [33m default [39m )
#&gt;   -&gt; data              :  232  rows  16  cols 
#&gt;   -&gt; data              :  tibbble converted into a data.frame 
#&gt;   -&gt; target variable   :  232  values 
#&gt;   -&gt; model_info        :  package stats , ver. 3.6.1 , task classification ( [33m default [39m ) 
#&gt;   -&gt; predict function  :  function(object, newdata) {     predict(object, newdata = newdata, type = &quot;response&quot;) } 
#&gt;   -&gt; predicted values  :  numerical, min =  0.001462956 , mean =  0.3019045 , max =  0.9982294  
#&gt;   -&gt; residual function :  difference between y and yhat ( [33m default [39m )
#&gt;   -&gt; residuals         :  numerical, min =  -0.977456 , mean =  0.01275069 , max =  0.9696249  
#&gt;  [32m A new explainer has been created! [39m
#&gt; Preparation of a new explainer is initiated
#&gt;   -&gt; model label       :  Random Forest 
#&gt;   -&gt; data              :  232  rows  16  cols 
#&gt;   -&gt; data              :  tibbble converted into a data.frame 
#&gt;   -&gt; target variable   :  232  values 
#&gt;   -&gt; model_info        :  package caret , ver. 6.0.86 , task Classification ( [33m default [39m ) 
#&gt;   -&gt; predict function  :  p_fun 
#&gt;   -&gt; predicted values  :  numerical, min =  0 , mean =  0.2938793 , max =  0.96  
#&gt;   -&gt; residual function :  difference between y and yhat ( [33m default [39m )
#&gt;   -&gt; residuals         :  numerical, min =  -0.92 , mean =  0.02077586 , max =  0.98  
#&gt;  [32m A new explainer has been created! [39m
#&gt; Preparation of a new explainer is initiated
#&gt;   -&gt; model label       :  Elastic Net Logistic Regression 
#&gt;   -&gt; data              :  232  rows  16  cols 
#&gt;   -&gt; data              :  tibbble converted into a data.frame 
#&gt;   -&gt; target variable   :  232  values 
#&gt;   -&gt; model_info        :  package caret , ver. 6.0.86 , task Classification ( [33m default [39m ) 
#&gt;   -&gt; predict function  :  p_fun 
#&gt;   -&gt; predicted values  :  numerical, min =  0.01095371 , mean =  0.2996897 , max =  0.9777987  
#&gt;   -&gt; residual function :  difference between y and yhat ( [33m default [39m )
#&gt;   -&gt; residuals         :  numerical, min =  -0.9032304 , mean =  0.01496552 , max =  0.9303534  
#&gt;  [32m A new explainer has been created! [39m
#&gt; Preparation of a new explainer is initiated
#&gt;   -&gt; model label       :  Support Vector Machine 
#&gt;   -&gt; data              :  232  rows  16  cols 
#&gt;   -&gt; data              :  tibbble converted into a data.frame 
#&gt;   -&gt; target variable   :  232  values 
#&gt;   -&gt; model_info        :  package caret , ver. 6.0.86 , task Classification ( [33m default [39m ) 
#&gt;   -&gt; predict function  :  p_fun 
#&gt;   -&gt; predicted values  :  numerical, min =  0.007386549 , mean =  0.2962761 , max =  0.9907738  
#&gt;   -&gt; residual function :  difference between y and yhat ( [33m default [39m )
#&gt;   -&gt; residuals         :  numerical, min =  -0.9440916 , mean =  0.01837911 , max =  0.9683094  
#&gt;  [32m A new explainer has been created! [39m
#&gt; Preparation of a new explainer is initiated
#&gt;   -&gt; model label       :  eXtreme Gradient Boosting 
#&gt;   -&gt; data              :  232  rows  16  cols 
#&gt;   -&gt; data              :  tibbble converted into a data.frame 
#&gt;   -&gt; target variable   :  232  values 
#&gt;   -&gt; model_info        :  package caret , ver. 6.0.86 , task Classification ( [33m default [39m ) 
#&gt;   -&gt; predict function  :  p_fun 
#&gt;   -&gt; predicted values  :  numerical, min =  0.005238354 , mean =  0.3006026 , max =  0.9944625  
#&gt;   -&gt; residual function :  difference between y and yhat ( [33m default [39m )
#&gt;   -&gt; residuals         :  numerical, min =  -0.9523564 , mean =  0.0140526 , max =  0.935866  
#&gt;  [32m A new explainer has been created! [39m</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">name</th>
<th align="right">recall</th>
<th align="right">precision</th>
<th align="right">f1</th>
<th align="right">accuracy</th>
<th align="right">auc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Elastic Net Logistic Regression</td>
<td align="right">0.56</td>
<td align="right">0.79</td>
<td align="right">0.66</td>
<td align="right">0.81</td>
<td align="right">0.87</td>
</tr>
<tr class="even">
<td align="left">Logistic Regression</td>
<td align="right">0.62</td>
<td align="right">0.76</td>
<td align="right">0.68</td>
<td align="right">0.82</td>
<td align="right">0.87</td>
</tr>
<tr class="odd">
<td align="left">eXtreme Gradient Boosting</td>
<td align="right">0.58</td>
<td align="right">0.75</td>
<td align="right">0.65</td>
<td align="right">0.81</td>
<td align="right">0.87</td>
</tr>
<tr class="even">
<td align="left">Support Vector Machine</td>
<td align="right">0.53</td>
<td align="right">0.85</td>
<td align="right">0.66</td>
<td align="right">0.82</td>
<td align="right">0.85</td>
</tr>
<tr class="odd">
<td align="left">Random Forest</td>
<td align="right">0.49</td>
<td align="right">0.77</td>
<td align="right">0.60</td>
<td align="right">0.79</td>
<td align="right">0.85</td>
</tr>
</tbody>
</table>
</div>
<div id="feature-importance" class="section level4">
<h4><span class="header-section-number">3.2.1.5</span> Feature importance</h4>
<p><img src="notebook_files/figure-html/ml_importance-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
</div>











            </section>

          </div>
        </div>
      </div>
<a href="prerequisites.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["notebook.pdf", "PDF"]],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": false,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
